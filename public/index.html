<script>
const $ = sel => document.querySelector(sel);
const logBox = $('#log');
const statusDot = $('#statusDot');
const statusTxt  = $('#statusTxt');
const startBtn  = $('#startBtn');
const hangBtn   = $('#hangBtn');
const testBtn   = $('#testBtn');
const voiceSel  = $('#voiceSel');
const remoteAudio = $('#remoteAudio');
const portraitEl = $('#portrait');

function log(s){ const at = new Date().toLocaleTimeString(); logBox.textContent += `[${at}] ${s}\n`; logBox.scrollTop = logBox.scrollHeight; }
function setStatus(state){ statusDot.className = 'dot ' + state; statusTxt.textContent = state; }

// ---------- Lip overlay UI ----------
const uiBar = document.createElement('div');
uiBar.className = 'row';
uiBar.style.marginTop = '10px';
uiBar.innerHTML = `
  <div style="color:#9aa4b2;font-size:13px">Target width</div>
  <input id="wSlider" type="range" min="60" max="520" value="260" style="width:180px">
  <div style="color:#9aa4b2;font-size:13px;margin-left:10px">Scale</div>
  <input id="sSlider" type="range" min="80" max="160" value="100" style="width:140px">
`;
portraitEl.parentElement.appendChild(uiBar);
const widthSlider = $('#wSlider');
const scaleSlider = $('#sSlider');

// Create mouth overlay
const mouth = document.createElement('img');
mouth.alt = 'mouth';
mouth.style.position = 'absolute';
mouth.style.left = '50%';
mouth.style.top =  '50%';
mouth.style.transform = 'translate(-50%, -50%)';
mouth.style.pointerEvents = 'auto';
mouth.style.userSelect = 'none';
mouth.style.mixBlendMode = 'normal';
mouth.style.filter = 'none';
mouth.style.display = 'none'; // hidden until frames load
mouth.draggable = false;
portraitEl.style.position = 'relative';
portraitEl.appendChild(mouth);

// anchor save/load
const anchorKey = 'emma_mouth_anchor_v1';
function saveAnchor(px, py){ localStorage.setItem(anchorKey, JSON.stringify({px,py})); log(`[anchor] saved x=${px.toFixed(3)}, y=${py.toFixed(3)}`); }
function loadAnchor(){
  try { return JSON.parse(localStorage.getItem(anchorKey)); } catch { return null; }
}

// click to anchor
portraitEl.addEventListener('click', (e) => {
  if (mouth.style.display === 'none') return;
  const r = portraitEl.getBoundingClientRect();
  const px = (e.clientX - r.left) / r.width;
  const py = (e.clientY - r.top) / r.height;
  placeMouth(px, py);
  saveAnchor(px, py);
});

// place & size
function placeMouth(px, py){
  const r = portraitEl.getBoundingClientRect();
  const target = parseInt(widthSlider.value, 10);
  const scale = parseInt(scaleSlider.value, 10) / 100;
  mouth.style.width = `${target}px`;
  mouth.style.left = `${(px * r.width)|0}px`;
  mouth.style.top  = `${(py * r.height)|0}px`;
  mouth.style.transform = `translate(-50%, -50%) scale(${scale})`;
}

// ----- load frames -----
const frameNames = ['f','p','g','i','l','o','u','v','say']; // filenames in /public/mouth/
const frames = [];
Promise.all(frameNames.map(n => new Promise(res=>{
  const img = new Image();
  img.onload = ()=>{ frames.push(img); res(); };
  img.onerror = ()=>{ log(`[frames] failed to load /mouth/${n}.png`); res(); };
  img.src = `/mouth/${n}.png`;
}))).then(()=>{
  if (frames.length){
    mouth.style.display = 'block';
    mouth.src = frames[0].src;
    log(`[frames] loaded ${frames.length}/${frameNames.length}`);

    // default anchor (center-ish)
    const saved = loadAnchor() || { px: 0.50, py: 0.58 };
    placeMouth(saved.px, saved.py);
  } else {
    log('[frames] no frames found (ensure /public/mouth/*.png exist and are lowercase)');
  }
});

widthSlider.addEventListener('input', ()=>{
  const saved = loadAnchor() || { px: 0.50, py: 0.58 };
  placeMouth(saved.px, saved.py);
});
scaleSlider.addEventListener('input', ()=>{
  const saved = loadAnchor() || { px: 0.50, py: 0.58 };
  placeMouth(saved.px, saved.py);
});

// animate frames by energy
let analyser = null, meterSrc = null;
function startMouthAnimation(stream){
  try{
    const ctx = new (window.AudioContext||window.webkitAudioContext)();
    const src = ctx.createMediaStreamSource(stream);
    const an = ctx.createAnalyser(); an.fftSize = 1024;
    src.connect(analyser = an); meterSrc = src;

    const buf = new Uint8Array(analyser.frequencyBinCount);
    let idx = 0, lastSwap = 0;

    function tick(now){
      if (!analyser) return;
      analyser.getByteFrequencyData(buf);
      // crude energy: average of low bands
      let sum = 0, n = 32; // first bins
      for (let i=0;i<n;i++) sum += buf[i];
      const energy = sum / (n*255); // 0..1

      // pick frame: quiet -> closed, loud -> open
      const band = Math.min(frames.length-1, Math.floor(energy * (frames.length)));
      if (frames[band] && (now - lastSwap > 40)) {
        mouth.src = frames[band].src;
        lastSwap = now;
      }
      requestAnimationFrame(tick);
    }
    requestAnimationFrame(tick);
  }catch(e){
    log('[lip] analyser failed: ' + (e?.message||e));
  }
}
function stopMouthAnimation(){
  analyser = null;
  if (meterSrc?.mediaStream) {
    // stream will be stopped in hangup()
  }
}

// ---------- Voice connection (unchanged) ----------
let pc = null;
let localStream = null;

function testSpeaker(){
  try{
    const ctx = new (window.AudioContext||window.webkitAudioContext)();
    const osc = ctx.createOscillator(); const g = ctx.createGain();
    osc.frequency.value = 880; g.gain.value = 0.05;
    osc.connect(g).connect(ctx.destination); osc.start();
    setTimeout(()=>{ osc.stop(); ctx.close(); }, 220);
    log('[speaker] test ping.');
  }catch(e){ log('[speaker] test failed: '+(e?.message||e)); }
}
testBtn.addEventListener('click', testSpeaker);

function setConnectedState(connected){
  setStatus(connected ? 'connected' : 'ended');
}

async function startSession(){
  if (pc) return;
  setStatus('connecting');
  log('[mic] requesting…');

  try {
    localStream = await navigator.mediaDevices.getUserMedia({ audio:true });
    log('[mic] granted.');
    // drive the mouth by mic energy (also reacts to your speech)
    startMouthAnimation(localStream);
  } catch (e) {
    log('[mic] denied: ' + (e?.message || e));
    setStatus('idle'); return;
  }

  pc = new RTCPeerConnection();
  // Send mic
  localStream.getTracks().forEach(tr => pc.addTrack(tr, localStream));
  // Receive remote audio
  const remoteStream = new MediaStream();
  pc.ontrack = e => {
    e.streams[0].getAudioTracks().forEach(t => remoteStream.addTrack(t));
    remoteAudio.srcObject = remoteStream;
  };

  pc.onconnectionstatechange = () => {
    log('[pc] state: ' + pc.connectionState);
    if (pc.connectionState === 'connected') setConnectedState(true);
    if (['failed','closed','disconnected'].includes(pc.connectionState)) setConnectedState(false);
  };

  const offer = await pc.createOffer({ offerToReceiveAudio:true });
  await pc.setLocalDescription(offer);
  log('[sdp] local offer created.');

  const voice = voiceSel.value || 'shimmer';
  log('[token] fetching…');
  const tokenR = await fetch(`/api/realtime-session?voice=${encodeURIComponent(voice)}`);
  if(!tokenR.ok){ log(`[token] error HTTP ${tokenR.status}`); throw new Error('token endpoint error'); }
  await tokenR.json();
  log('[token] ok.');

  log('[sdp] exchanging via /api/realtime-session (POST)…');
  const post = await fetch('/api/realtime-session', {
    method: 'POST',
    headers: { 'Content-Type':'application/json' },
    body: JSON.stringify({ sdp: offer.sdp, voice })
  });
  if(!post.ok){
    const t = await post.text().catch(()=> '');
    log(`[sdp] server POST failed: ${post.status} ${t}`);
    throw new Error('SDP exchange failed.');
  }
  const { answer } = await post.json();
  await pc.setRemoteDescription({ type:'answer', sdp: answer });
  log('[sdp] answer set. WebRTC completing…');
}

async function hangup(){
  stopMouthAnimation();
  if (pc) { try{ pc.close(); }catch{} pc = null; }
  if (localStream) { localStream.getTracks().forEach(t => t.stop()); localStream = null; }
  setStatus('ended');
  log('[call] ended.');
}

startBtn.addEventListener('click', () => startSession().catch(e=>{ log('[error] '+(e?.message||e)); setStatus('ended'); }));
hangBtn.addEventListener('click', hangup);
</script>
