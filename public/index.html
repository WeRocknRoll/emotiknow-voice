<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>EmotiKnow — Emma (Voice Companion)</title>
  <style>
    :root {
      --bg: #0b0f14;
      --panel: #121822;
      --text: #eef3ff;
      --muted: #9fb0ca;
      --accent: #7c9cff;
      --ok: #79d08a;
      --err: #ff7e7e;
      --btn: #222b3b;
      --btn-hover: #2b374d;
      --btn-primary: #6c63ff;
      --btn-primary-hover: #5a53e8;
    }
    html, body {
      background: var(--bg);
      color: var(--text);
      font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Inter, "Helvetica Neue", Arial, "Apple Color Emoji","Segoe UI Emoji";
      margin: 0;
      padding: 0;
    }
    .wrap {
      max-width: 1200px;
      margin: 24px auto 56px;
      padding: 0 16px;
    }
    h1 {
      font-weight: 800;
      letter-spacing: 0.2px;
      margin: 0 0 8px;
      font-size: clamp(22px, 3.2vw, 32px);
    }
    .subtle { color: var(--muted); }

    .grid {
      display: grid;
      grid-template-columns: 1.1fr 0.9fr;
      gap: 18px;
    }
    @media (max-width: 980px) {
      .grid { grid-template-columns: 1fr; }
    }

    .panel {
      background: var(--panel);
      border-radius: 14px;
      border: 1px solid #1c2433;
      overflow: hidden;
    }
    .panel-head {
      display: flex;
      align-items: center;
      justify-content: space-between;
      padding: 12px 14px;
      border-bottom: 1px solid #1c2433;
      background: linear-gradient(180deg, rgba(255,255,255,0.02), transparent);
    }
    .panel-body { padding: 12px; }

    .vis {
      position: relative;
      width: 100%;
      aspect-ratio: 16/10; /* keeps consistent canvas scaling */
      background: #0e141f;
      overflow: hidden;
      border-radius: 10px;
      user-select: none;
    }
    .portrait {
      position: absolute;
      inset: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
      pointer-events: none;
      filter: saturate(1.02) contrast(1.02);
    }
    canvas#mouth {
      position: absolute;
      inset: 0;
      width: 100%;
      height: 100%;
      pointer-events: none;
    }
    /* crosshair target overlay (click-to-place) */
    .crosshair {
      --size: 22px;
      position: absolute;
      width: var(--size);
      height: var(--size);
      border-radius: 50%;
      border: 2px solid rgba(255,255,255,0.8);
      background: rgba(255, 66, 66, 0.55);
      box-shadow: 0 0 0 2px rgba(0,0,0,0.25);
      transform: translate(-50%, -50%);
      pointer-events: none;
    }

    .controls {
      display: flex;
      gap: 10px;
      flex-wrap: wrap;
      align-items: center;
      margin-top: 12px;
    }
    button, select {
      background: var(--btn);
      color: var(--text);
      border: 1px solid #2a374f;
      border-radius: 10px;
      padding: 9px 12px;
      font-size: 14px;
      cursor: pointer;
    }
    button:hover { background: var(--btn-hover); }
    .primary { background: var(--btn-primary); border-color: #5750ff; }
    .primary:hover { background: var(--btn-primary-hover); }
    .danger { background: #3a2530; border-color: #533042; color: #ffc8d1; }
    .danger:hover { background: #452838; }
    .ghost { background: transparent; border-color: #2b3850; }

    .status {
      font-size: 13px;
      margin-left: auto;
      padding: 6px 8px;
      border-radius: 8px;
      background: #182233;
      color: var(--muted);
    }
    .status.ok { color: var(--ok); }
    .status.err { color: var(--err); }

    pre.log {
      font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;
      background: #0d1320;
      color: #cfe3ff;
      border-radius: 10px;
      border: 1px solid #1b2334;
      padding: 12px;
      margin: 0;
      height: clamp(240px, 38vh, 420px);
      overflow: auto;
      line-height: 1.35;
      font-size: 13px;
      white-space: pre-wrap;
    }
    .tip {
      color: var(--muted);
      font-size: 13px;
      margin-top: 8px;
    }
    .right { text-align: right; }
  </style>
</head>
<body>
  <div class="wrap">
    <h1>EmotiKnow — Emma (Voice Companion)</h1>
    <div class="subtle">Click <b>Start</b> once to allow your microphone. Talk naturally; Emma replies in real time. Her portrait lip-syncs to the audio.</div>

    <div class="grid" style="margin-top:16px">
      <!-- Left: visual + controls -->
      <div class="panel">
        <div class="panel-head">
          <div>Emma (portrait)</div>
          <div id="callState" class="status">idle</div>
        </div>

        <div class="panel-body">
          <div id="vis" class="vis" title="Click near the lips to re-anchor mouth; drag to fine-tune.">
            <img id="portrait" class="portrait" src="/Emma_EmotiKnow_Companion.png" alt="Emma portrait" />
            <canvas id="mouth"></canvas>
            <div id="target" class="crosshair" style="left: 50%; top: 50%;"></div>
          </div>

          <div class="controls">
            <button id="start" class="primary">Start</button>
            <button id="hangup" class="danger">Hang Up</button>

            <select id="voice">
              <option value="shimmer" selected>Shimmer (female, bright)</option>
              <option value="coral">Coral (female, clear)</option>
              <option value="sage">Sage (female, soft)</option>
              <option value="marin">Marin (female, warm)</option>
              <option value="ballad">Ballad (feminine, lyrical)</option>
              <option value="verse">Verse (neutral)</option>
              <option value="alloy">Alloy (neutral)</option>
              <option value="echo">Echo</option>
              <option value="ash">Ash</option>
              <option value="cedar">Cedar</option>
            </select>

            <button id="test" class="ghost">Test speaker</button>

            <div id="status" class="status right">status: <span id="statusText">idle</span></div>
          </div>

          <div class="tip">
            Tip: If you don’t hear Emma, click <b>Test speaker</b>, then click <b>Start</b> again (autoplay can be blocked).
            Click the portrait to re-anchor lips; your position is saved for this browser.
          </div>
        </div>
      </div>

      <!-- Right: log -->
      <div class="panel">
        <div class="panel-head"><div>Diagnostics</div></div>
        <div class="panel-body">
          <pre id="log" class="log"></pre>
        </div>
      </div>
    </div>
  </div>

  <!-- Hidden audio for remote stream -->
  <audio id="remote" autoplay playsinline></audio>

  <script>
    // ======= DOM elements =======
    const startBtn   = document.getElementById('start');
    const hangupBtn  = document.getElementById('hangup');
    const testBtn    = document.getElementById('test');
    const voiceSel   = document.getElementById('voice');
    const statusEl   = document.getElementById('statusText');
    const callState  = document.getElementById('callState');
    const logEl      = document.getElementById('log');

    const vis        = document.getElementById('vis');
    const img        = document.getElementById('portrait');
    const canvas     = document.getElementById('mouth');
    const target     = document.getElementById('target');
    const remoteEl   = document.getElementById('remote');

    const ctx = canvas.getContext('2d', { alpha: true });

    // ======= Mouth anchor (image-space) =======
    // Default for everyone (your measured values): x=523, y=215.
    const DEFAULT_MOUTH = { x: 523, y: 215 };

    function getSavedMouth() {
      try {
        const raw = localStorage.getItem('emma_mouth_anchor');
        if (!raw) return { ...DEFAULT_MOUTH };
        const obj = JSON.parse(raw);
        if (typeof obj.x === 'number' && typeof obj.y === 'number') return obj;
      } catch {}
      return { ...DEFAULT_MOUTH };
    }
    function saveMouth(pt) {
      localStorage.setItem('emma_mouth_anchor', JSON.stringify(pt));
      log(`Saved mouth: x=${pt.x}, y=${pt.y}`);
    }
    let mouthImg = getSavedMouth();

    // ======= Layout helpers =======
    function updateCanvasSize() {
      // match canvas pixels to CSS box for crisp drawing
      const rect = vis.getBoundingClientRect();
      canvas.width  = Math.max(2, Math.floor(rect.width  * devicePixelRatio));
      canvas.height = Math.max(2, Math.floor(rect.height * devicePixelRatio));
      canvas.style.width  = rect.width + 'px';
      canvas.style.height = rect.height + 'px';
      drawMouth(0); // refresh marker
      placeTarget();
    }
    function placeTarget() {
      // translate image-space mouth (img natural space) to CSS box
      const rect = vis.getBoundingClientRect();
      const w = img.naturalWidth || 1920;
      const h = img.naturalHeight || 1200;

      // Determine how the image maps into the box (object-fit: cover math)
      const boxW = rect.width, boxH = rect.height;
      const imgRatio = w / h, boxRatio = boxW / boxH;

      let drawW, drawH, offsetX, offsetY;
      if (imgRatio > boxRatio) {
        // image is "wider" -> height fits, crop x
        drawH = boxH;
        drawW = boxH * imgRatio;
        offsetX = (boxW - drawW) / 2;
        offsetY = 0;
      } else {
        // image is "taller" -> width fits, crop y
        drawW = boxW;
        drawH = boxW / imgRatio;
        offsetX = 0;
        offsetY = (boxH - drawH) / 2;
      }

      const scaleX = drawW / w;
      const scaleY = drawH / h;
      const cssX = offsetX + mouthImg.x * scaleX;
      const cssY = offsetY + mouthImg.y * scaleY;

      target.style.left = cssX + 'px';
      target.style.top  = cssY + 'px';
    }

    // Handle click to set mouth anchor
    let dragging = false;
    vis.addEventListener('pointerdown', (e) => {
      dragging = true;
      setAnchorFromEvent(e);
    });
    vis.addEventListener('pointermove', (e) => {
      if (!dragging) return;
      setAnchorFromEvent(e);
    });
    window.addEventListener('pointerup', () => dragging = false);

    function setAnchorFromEvent(e) {
      const rect = vis.getBoundingClientRect();
      const boxX = e.clientX - rect.left;
      const boxY = e.clientY - rect.top;

      // invert object-fit: cover mapping to get image-space coords
      const w = img.naturalWidth || 1920;
      const h = img.naturalHeight || 1200;
      const boxW = rect.width, boxH = rect.height;
      const imgRatio = w / h, boxRatio = boxW / boxH;

      let drawW, drawH, offsetX, offsetY;
      if (imgRatio > boxRatio) {
        drawH = boxH;
        drawW = boxH * imgRatio;
        offsetX = (boxW - drawW) / 2;
        offsetY = 0;
      } else {
        drawW = boxW;
        drawH = boxW / imgRatio;
        offsetX = 0;
        offsetY = (boxH - drawH) / 2;
      }

      const xOnImage = (boxX - offsetX) * (w / drawW);
      const yOnImage = (boxY - offsetY) * (h / drawH);

      mouthImg = {
        x: Math.max(0, Math.min(w, xOnImage)),
        y: Math.max(0, Math.min(h, yOnImage))
      };
      saveMouth(mouthImg);
      placeTarget();
    }

    // ======= Logging / status =======
    function log(msg) {
      const ts = new Date().toLocaleTimeString();
      logEl.textContent += `[${ts}] ${msg}\n`;
      logEl.scrollTop = logEl.scrollHeight;
    }
    function setStatus(txt, ok = false, err = false) {
      statusEl.textContent = txt;
      callState.textContent = txt;
      callState.classList.toggle('ok', ok);
      callState.classList.toggle('err', err);
    }

    // ======= WebRTC + OpenAI Realtime =======
    let pc = null;
    let localStream = null;
    let analyser = null;
    let rafId = null;

    async function start() {
      try {
        setStatus('requesting mic…');
        log('Requesting microphone…');
        localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        setStatus('mic granted');

        // Token for ephemeral key + metadata
        const voice = voiceSel.value || 'shimmer';
        const tokenRes = await fetch(`/api/realtime-session?voice=${encodeURIComponent(voice)}`);
        if (!tokenRes.ok) {
          const body = await tokenRes.text();
          throw new Error(`Token endpoint error ${tokenRes.status}: ${body}`);
        }
        const token = await tokenRes.json();
        log(`Token response status: ${tokenRes.status}`);

        // Create PC
        pc = new RTCPeerConnection();
        pc.onconnectionstatechange = () => {
          log(`pc state: ${pc.connectionState}`);
          if (['disconnected','failed','closed'].includes(pc.connectionState)) {
            setStatus('ended'); cleanup();
          }
        };
        // Play remote audio
        pc.ontrack = (e) => {
          remoteEl.srcObject = e.streams[0];
          setupMouthAnalyzer(remoteEl);
          log('Remote audio stream received.');
        };
        // Add mic track
        localStream.getTracks().forEach(t => pc.addTrack(t, localStream));

        // Offer
        const offer = await pc.createOffer({ offerToReceiveAudio: true, offerToReceiveVideo: false });
        await pc.setLocalDescription(offer);

        // POST SDP to OpenAI Realtime
        setStatus('connecting');
        log(`POSTing SDP to: https://api.openai.com/v1/realtime?model=${token.model || 'gpt-4o-mini-realtime-preview'}`);
        const sdpRes = await fetch(`https://api.openai.com/v1/realtime?model=${encodeURIComponent(token.model || 'gpt-4o-mini-realtime-preview')}`, {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${token.client_secret.value}`,
            'Content-Type': 'application/sdp',
            'OpenAI-Beta': 'realtime=v1'
          },
          body: offer.sdp
        });

        log(`SDP POST status: ${sdpRes.status}`);
        if (!sdpRes.ok) {
          const body = await sdpRes.text();
          throw new Error(`SDP exchange failed: ${body}`);
        }
        const answer = { type: 'answer', sdp: await sdpRes.text() };
        await pc.setRemoteDescription(answer);

        setStatus('connected', true);
        log('Session established on gpt-4o-mini-realtime-preview.');
      } catch (err) {
        console.error(err);
        log(`Error: ${err.message}`);
        setStatus('error', false, true);
        cleanup();
      }
    }

    function hangup() {
      log('Call ended. (user)');
      setStatus('ended');
      cleanup();
    }

    function cleanup() {
      try { if (pc) pc.close(); } catch {}
      pc = null;
      if (localStream) {
        localStream.getTracks().forEach(t => t.stop());
        localStream = null;
      }
      stopMouthAnalyzer();
    }

    // ======= Test speaker (autoplay unlock) =======
    async function testSpeaker() {
      const ctx = new (window.AudioContext || window.webkitAudioContext)();
      const osc = ctx.createOscillator();
      const gain = ctx.createGain();
      gain.gain.value = 0.05;
      osc.type = 'sine';
      osc.frequency.value = 880;
      osc.connect(gain).connect(ctx.destination);
      osc.start();
      await new Promise(r => setTimeout(r, 300));
      osc.stop();
      await ctx.close();
    }

    // ======= Mouth animation (Web Audio API) =======
    function setupMouthAnalyzer(audioEl) {
      stopMouthAnalyzer();

      const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      const src = audioCtx.createMediaElementSource(audioEl);
      analyser = audioCtx.createAnalyser();
      analyser.fftSize = 2048;
      src.connect(analyser);
      analyser.connect(audioCtx.destination); // so we can hear audio

      const buffer = new Uint8Array(analyser.fftSize);

      const tick = () => {
        analyser.getByteTimeDomainData(buffer);
        // Compute "openness" from waveform variance around midline
        let sum = 0;
        for (let i = 0; i < buffer.length; i++) {
          const v = buffer[i] - 128;
          sum += v * v;
        }
        const rms = Math.sqrt(sum / buffer.length);  // ~0..90
        // Normalize roughly 0..1
        const open = Math.min(1, rms / 35);

        drawMouth(open);
        rafId = requestAnimationFrame(tick);
      };
      tick();
    }

    function stopMouthAnalyzer() {
      if (rafId) cancelAnimationFrame(rafId), rafId = null;
      drawMouth(0);
    }

    function drawMouth(openFactor) {
      // clear
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      // compute CSS mapping to canvas pixels
      const rect = vis.getBoundingClientRect();
      const w = img.naturalWidth || 1920;
      const h = img.naturalHeight || 1200;
      const boxW = rect.width, boxH = rect.height;
      const imgRatio = w / h, boxRatio = boxW / boxH;

      let drawW, drawH, offsetX, offsetY;
      if (imgRatio > boxRatio) {
        drawH = boxH;
        drawW = boxH * imgRatio;
        offsetX = (boxW - drawW) / 2;
        offsetY = 0;
      } else {
        drawW = boxW;
        drawH = boxW / imgRatio;
        offsetX = 0;
        offsetY = (boxH - drawH) / 2;
      }

      const scaleX = (canvas.width  / boxW) * (drawW / w);
      const scaleY = (canvas.height / boxH) * (drawH / h);
      const px = (offsetX + (mouthImg.x / w) * drawW) * (canvas.width / boxW);
      const py = (offsetY + (mouthImg.y / h) * drawH) * (canvas.height / boxH);

      // draw a soft oval that opens with audio; subtle & natural
      const baseW = 28 * devicePixelRatio;      // base mouth width (px)
      const baseH = 10 * devicePixelRatio;      // base closed height
      const amp   = 22 * devicePixelRatio;      // how much it opens

      const mw = baseW;
      const mh = baseH + amp * openFactor;

      ctx.save();
      ctx.translate(px, py);
      // inner lip (darker)
      ctx.fillStyle = 'rgba(255, 88, 96, 0.85)';
      drawOval(ctx, 0, 0, mw, mh);
      ctx.fill();

      // inner shadow to soften
      const grad = ctx.createRadialGradient(0, 0, 2, 0, 0, mw);
      grad.addColorStop(0, 'rgba(255,160,170,0.75)');
      grad.addColorStop(1, 'rgba(255, 60, 72, 0.2)');
      ctx.fillStyle = grad;
      drawOval(ctx, 0, 0, mw * 0.92, mh * 0.8);
      ctx.fill();

      // subtle outer glow for depth
      ctx.strokeStyle = 'rgba(0,0,0,0.2)';
      ctx.lineWidth = 2 * devicePixelRatio;
      drawOval(ctx, 0, 0, mw, mh);
      ctx.stroke();
      ctx.restore();
    }

    function drawOval(ctx, cx, cy, rx, ry) {
      ctx.beginPath();
      ctx.ellipse(cx, cy, rx, ry, 0, 0, Math.PI * 2);
      ctx.closePath();
    }

    // ======= Events =======
    startBtn.addEventListener('click', start);
    hangupBtn.addEventListener('click', hangup);
    testBtn.addEventListener('click', testSpeaker);

    // Initial layout + crosshair placement
    function init() {
      updateCanvasSize();
      placeTarget();
      setStatus('idle');
      log('Ready. Click Start and speak. If you do not hear audio, press Test speaker then Start again.');
    }
    window.addEventListener('resize', updateCanvasSize);
    img.addEventListener('load', () => { updateCanvasSize(); placeTarget(); });
    init();
  </script>
</body>
</html>
