<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>EmotiKnow — Emma (Voice Companion)</title>
  <style>
    :root { --bg:#0d0f13; --panel:#12151b; --muted:#8aa0b6; --accent:#7c5cff; --ok:#73e6a0; }
    *{box-sizing:border-box} body{margin:0;background:var(--bg);color:#e9f0f7;
      font:15px/1.5 system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial}
    .wrap{max-width:1100px;margin:32px auto;padding:0 16px}
    h1{font-weight:800;letter-spacing:.2px;margin:0 0 10px}
    .hint{color:var(--muted);margin-bottom:16px}
    .grid{display:grid;grid-template-columns:1fr 420px;gap:16px}
    .panel{background:var(--panel);border-radius:14px;padding:12px}
    .row{display:flex;gap:8px;align-items:center;margin-top:10px;flex-wrap:wrap}
    button,select{background:#1a1f29;border:1px solid #232a36;color:#e9f0f7;border-radius:10px;
      padding:10px 14px;font-weight:600;cursor:pointer}
    button.primary{background:var(--accent);border-color:var(--accent)}
    button.warn{background:#252a33;border-color:#2c3442}
    button:disabled{opacity:.6;cursor:not-allowed}
    #status{color:var(--ok);font-weight:700}
    #log{height:420px;overflow:auto;background:#0e1218;border-radius:12px;padding:12px;
      font:13px/1.45 ui-monospace,Menlo,Consolas,monospace;white-space:pre-wrap}
    canvas{width:100%;height:auto;border-radius:12px;background:#000}
    small.kb{color:var(--muted)}
  </style>
</head>
<body>
  <div class="wrap">
    <h1>EmotiKnow — Emma (Voice Companion)</h1>
    <div class="hint">Click <b>Start</b> once to allow your microphone. Talk naturally; Emma replies in real time.
      Her portrait lip-syncs to the audio.</div>

    <div class="grid">
      <!-- Left: Emma canvas -->
      <div class="panel">
        <div style="font-weight:700;margin:4px 0 8px 4px">Emma (portrait)</div>
        <canvas id="portrait" width="1600" height="960"></canvas>

        <div class="row">
          <button id="start" class="primary">Start</button>
          <button id="hangup" class="warn">Hang Up</button>

          <select id="voice">
            <option value="shimmer" selected>Shimmer (female, bright)</option>
            <option value="coral">Coral (female, clear)</option>
            <option value="sage">Sage (female, soft)</option>
            <option value="marin">Marin (female, warm)</option>
            <option value="ballad">Ballad (feminine, lyrical)</option>
            <option value="verse">Verse (neutral)</option>
            <option value="alloy">Alloy (neutral)</option>
            <option value="echo">Echo</option>
            <option value="ash">Ash</option>
            <option value="cedar">Cedar</option>
          </select>

          <button id="testspk">Test speaker</button>
          <div style="margin-left:auto;color:var(--muted)">status: <span id="status">ended</span></div>
        </div>
        <div class="row"><small class="kb">
          Tip: If you don’t hear Emma, click <b>Test speaker</b>, then click <b>Start</b> again (autoplay can be blocked).
          Overlay keys: <b>Click</b>=place lips, <b>←↑→↓</b>=nudge (Shift=10px), <b>Enter</b>=save, <b>O</b>=toggle, <b>R</b>=reset.
        </small></div>
      </div>

      <!-- Right: console log -->
      <div class="panel">
        <div id="log"></div>
      </div>
    </div>
  </div>

<script>
/* ------------------------------ UI helpers ------------------------------ */
const logEl = document.getElementById('log');
function log(msg){ const t=new Date().toLocaleTimeString(); logEl.textContent += `[${t}] ${msg}\n`; logEl.scrollTop=logEl.scrollHeight; }
const setStatus = s => document.getElementById('status').textContent = s;

/* ------------------------------ Canvas + Image ------------------------------ */
const canvas = document.getElementById('portrait');
const ctx = canvas.getContext('2d', { alpha: false });
let BASE_W = 1600, BASE_H = 960;     // will swap to image natural size on load
const dpr = Math.min(3, window.devicePixelRatio || 1);

/* Cache-bust the image so you always see new changes */
const img = new Image();
img.src = '/Emma_EmotiKnow_Companion.png?v=4';  // <-- edit filename if needed

img.onload = () => {
  BASE_W = img.naturalWidth  || BASE_W;
  BASE_H = img.naturalHeight || BASE_H;
  resizeToCSS();
  drawAvatar(0);
};

function resizeToCSS(){
  const rect = canvas.getBoundingClientRect();
  const w = Math.max(1, Math.floor(rect.width * dpr));
  const h = Math.max(1, Math.floor(rect.width * (BASE_H/BASE_W) * dpr));
  if (canvas.width !== w || canvas.height !== h){
    canvas.width = w; canvas.height = h;
    ctx.imageSmoothingEnabled = true; ctx.imageSmoothingQuality = 'high';
  }
}
window.addEventListener('resize', () => { resizeToCSS(); drawAvatar(0); });

/* ------------------------------ Mouth calibrator ------------------------------ */
const MOUTH_KEY = 'emmaMouth';
function loadMouth(){ try { return JSON.parse(localStorage.getItem(MOUTH_KEY)) || null; } catch { return null; } }
function saveMouth(m){ localStorage.setItem(MOUTH_KEY, JSON.stringify(m)); log(`Saved mouth: x=${m.x}, y=${m.y}`); }

let MOUTH = loadMouth() || { x: 800, y: 520, w: 88, h0: 10, hmax: 70 };
let overlayOn = true, showPickHint = !loadMouth();

const mapX = x => x * (canvas.width  / BASE_W);
const mapY = y => y * (canvas.height / BASE_H);
const mapW = w => w * (canvas.width  / BASE_W);
const mapH = h => h * (canvas.height / BASE_H);

canvas.addEventListener('mousedown', (e) => {
  showPickHint = false;
  const rect = canvas.getBoundingClientRect();
  const cx = (e.clientX - rect.left) * dpr;
  const cy = (e.clientY - rect.top)  * dpr;
  const imgX = Math.round(cx * (BASE_W / canvas.width));
  const imgY = Math.round(cy * (BASE_H / canvas.height));
  MOUTH.x = imgX; MOUTH.y = imgY;
  drawAvatar(0);
  log(`Picked mouth at (image space) x=${imgX}, y=${imgY}`);
});

window.addEventListener('keydown', (e) => {
  const step = e.shiftKey ? 10 : 2;
  let changed = false;
  if (e.key === 'ArrowLeft')  { MOUTH.x = Math.max(0, MOUTH.x - step); changed=true; }
  if (e.key === 'ArrowRight') { MOUTH.x = Math.min(BASE_W, MOUTH.x + step); changed=true; }
  if (e.key === 'ArrowUp')    { MOUTH.y = Math.max(0, MOUTH.y - step); changed=true; }
  if (e.key === 'ArrowDown')  { MOUTH.y = Math.min(BASE_H, MOUTH.y + step); changed=true; }
  if (e.key.toLowerCase() === 'o'){ overlayOn = !overlayOn; changed=true; }
  if (e.key === 'Enter'){ saveMouth(MOUTH); }
  if (e.key.toLowerCase() === 'r'){
    localStorage.removeItem(MOUTH_KEY);
    MOUTH = { x: 800, y: 520, w: 88, h0: 10, hmax: 70 };
    showPickHint = true; changed=true;
  }
  if (changed) drawAvatar(0);
});

function drawOverlay(){
  if (!overlayOn) return;
  const cx = mapX(MOUTH.x), cy = mapY(MOUTH.y);
  const r = Math.max(6, mapW(6));
  ctx.save();
  ctx.lineWidth = 1 * dpr; ctx.strokeStyle='rgba(255,255,255,.65)';
  ctx.beginPath(); ctx.moveTo(cx-30,cy); ctx.lineTo(cx+30,cy); ctx.stroke();
  ctx.beginPath(); ctx.moveTo(cx,cy-30); ctx.lineTo(cx,cy+30); ctx.stroke();
  ctx.fillStyle='rgba(255,64,64,.9)'; ctx.beginPath(); ctx.arc(cx,cy,r,0,Math.PI*2); ctx.fill();
  ctx.fillStyle='rgba(255,255,255,.85)'; ctx.font=`${12*dpr}px system-ui,sans-serif`;
  ctx.fillText(`Mouth (img): x=${MOUTH.x} y=${MOUTH.y}`, 12*dpr, 18*dpr);
  if (showPickHint) ctx.fillText(`Click the center of the lips`, 12*dpr, 34*dpr);
  ctx.restore();
}

/* ------------------------------ Lip-sync drawing ------------------------------ */
/* amplitude ∈ [0..1] from the remote audio power */
function drawAvatar(amplitude){
  // background portrait
  ctx.drawImage(img, 0, 0, BASE_W, BASE_H, 0, 0, canvas.width, canvas.height);

  // mouth ellipse (replace fill with your patch if you later add a real blended mouth)
  const cx = mapX(MOUTH.x), cy = mapY(MOUTH.y);
  const mouthW = mapW(MOUTH.w);
  const mouthH = mapH(MOUTH.h0 + (MOUTH.hmax - MOUTH.h0) * amplitude);
  ctx.save();
  ctx.fillStyle = 'rgba(255,64,64,.35)';  // semi-transparent to visualize
  ctx.beginPath(); ctx.ellipse(cx, cy, mouthW/2, mouthH/2, 0, 0, Math.PI*2); ctx.fill();
  ctx.restore();

  drawOverlay();
}

/* ------------------------------ WebRTC (Emma) ------------------------------ */
let pc = null, localStream = null, remoteStream = null;
const startBtn = document.getElementById('start');
const hangupBtn = document.getElementById('hangup');
const voiceSel  = document.getElementById('voice');
const testBtn   = document.getElementById('testspk');

testBtn.onclick = async () => {
  try {
    const a = new Audio();
    a.src = 'data:audio/wav;base64,UklGRiQAAABXQVZFZm10IBAAAAABAAEAESsAACJWAAACABYAAABkYXRhAgAAAAAA'; // tiny click
    await a.play();
  } catch(e){ /* ignored */ }
};

hangupBtn.onclick = () => { if (pc) { pc.close(); pc=null; } setStatus('ended'); log('Call ended.'); };

startBtn.onclick = async () => {
  try {
    setStatus('starting');
    log('Requesting microphone…');
    localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    log('Mic granted.');

    // 1) ask your server for a session token
    const voice = encodeURIComponent(voiceSel.value);
    const tokenRes = await fetch(`/api/realtime-session?voice=${voice}`); // <-- edit route if needed
    if (!tokenRes.ok){
      const body = await tokenRes.text();
      log(`Token error ${tokenRes.status}: ${body}`); setStatus('error'); return;
    }
    const token = await tokenRes.json();
    log(`Token response status: ${tokenRes.status}`);

    // 2) create PC and wire streams
    pc = new RTCPeerConnection();
    remoteStream = new MediaStream();
    const remoteAudio = new Audio(); remoteAudio.autoplay = true;
    remoteAudio.srcObject = remoteStream;

    pc.ontrack = (e) => {
      remoteStream.addTrack(e.track);
      // audio analyser for amplitude
      startAnalyser(remoteAudio);
      log('Remote audio stream received.');
    };
    pc.onconnectionstatechange = () => {
      log(`pc state: ${pc.connectionState}`);
      if (['disconnected','failed','closed'].includes(pc.connectionState)) {
        setStatus('ended'); log('Call ended.'); stopAnalyser();
      }
    };

    // 3) add mic tracks
    localStream.getTracks().forEach(t => pc.addTrack(t, localStream));

    // 4) offer → your token endpoint expects standard SDP exchange
    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);

    // POST SDP to OpenAI with the token (standard Realtime REST exchange)
    const sdpRes = await fetch('https://api.openai.com/v1/realtime?model=' + encodeURIComponent(token.model), {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${token.client_secret.value}`,
        'Content-Type': 'application/sdp',
        'OpenAI-Beta': 'realtime=v1'
      },
      body: offer.sdp
    });

    if (!sdpRes.ok) {
      const t = await sdpRes.text();
      log(`SDP POST failed: ${sdpRes.status} ${t}`); setStatus('error'); return;
    }
    const answerSDP = await sdpRes.text();
    await pc.setRemoteDescription({ type:'answer', sdp: answerSDP });

    setStatus('live (hands-free)');
    log(`Session established on ${token.model}. Voice: ${voiceSel.value}.`);
  } catch (err) {
    log('Error: ' + (err?.message||String(err)));
    setStatus('error');
  }
};

/* ------------------------------ Audio analyser → amplitude ------------------------------ */
let rafId = 0, analyser=null, dataArr=null, audioCtx=null, srcNode=null;

function startAnalyser(htmlAudio){
  stopAnalyser();
  audioCtx = new (window.AudioContext||window.webkitAudioContext)();
  analyser = audioCtx.createAnalyser(); analyser.fftSize = 1024;
  dataArr = new Uint8Array(analyser.frequencyBinCount);
  srcNode = audioCtx.createMediaElementSource(htmlAudio);
  srcNode.connect(analyser); analyser.connect(audioCtx.destination);

  let last = performance.now();
  const loop = () => {
    rafId = requestAnimationFrame(loop);
    analyser.getByteTimeDomainData(dataArr);

    // measure amplitude in time domain (simple RMS)
    let sum=0;
    for (let i=0;i<dataArr.length;i++){ const v = (dataArr[i]-128)/128; sum += v*v; }
    let rms = Math.sqrt(sum/dataArr.length);
    rms = Math.min(1, Math.max(0, (rms - 0.02) * (1/(0.35)) )); // gate & scale a bit

    drawAvatar(rms);
  };
  loop();
}

function stopAnalyser(){
  if (rafId) cancelAnimationFrame(rafId), rafId=0;
  if (audioCtx){ try{ audioCtx.close(); }catch{} audioCtx=null; }
  analyser=null; dataArr=null;
}

/* ------------------------------ Boot ------------------------------ */
setStatus('ended');
log('Ready. Click Start and speak. If you do not hear audio, press Test speaker then Start again.');
</script>
</body>
</html>
