<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>EmotiKnow — Emma (Voice Companion)</title>
  <style>
    :root{
      --bg:#0f1117; --panel:#151b23; --ink:#e6e8ef; --muted:#9aa3b2; --accent:#8ab4ff;
      --ok:#22c55e; --warn:#f59e0b; --err:#ef4444;
    }
    *{box-sizing:border-box}
    html,body{height:100%}
    body{
      margin:0; background:var(--bg); color:var(--ink);
      font:500 15px/1.45 system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji";
      display:grid; place-items:start; padding:24px;
    }
    h1{margin:0 0 14px; letter-spacing:.3px}
    .row{display:grid; grid-template-columns: 1fr .8fr; gap:16px; align-items:start}
    @media (max-width:1000px){ .row{grid-template-columns:1fr} }

    .panel{
      background:var(--panel); border:1px solid #202937; border-radius:14px; padding:16px;
      box-shadow: 0 10px 30px rgba(0,0,0,.35);
    }
    .canvas{
      position:relative; overflow:hidden; border-radius:12px; background:#000;
      display:grid; place-items:center; min-height:420px;
    }
    .inner{
      position:relative; max-width:100%; max-height:72vh;
      aspect-ratio: 1920/1200; /* Portrait aspect; keeps scaling correct */
    }
    #portrait{
      display:block; width:100%; height:100%; object-fit:contain; background:#000;
      user-select:none; -webkit-user-drag:none;
    }
    /* Mouth overlay */
    #mouth{
      position:absolute; left:50%; top:50%;
      transform:translate(-50%,-50%) scale(1);
      width:260px; /* controlled by slider + anchor save */
      filter: saturate(0.95) contrast(0.95) brightness(0.98);
      pointer-events:none; /* clicks go to portrait for anchoring */
      image-rendering:auto;
    }

    .controls{display:grid; gap:12px}
    .controls .row3{display:grid; grid-template-columns: repeat(3, minmax(180px, 1fr)); gap:14px}
    .controls .row2{display:grid; grid-template-columns: repeat(2, minmax(220px, 1fr)); gap:14px}
    .controls label{display:grid; gap:6px; font-weight:600; color:var(--muted)}
    .controls input[type="range"]{width:100%}
    .btns{display:flex; gap:10px; flex-wrap:wrap}
    button{
      background:#1d2735; color:var(--ink); border:1px solid #263041; border-radius:10px;
      padding:10px 14px; cursor:pointer; font-weight:700;
    }
    button.primary{background:#1e293b; border-color:#2d3a4f}
    button:hover{filter:brightness(1.08)}
    small.hint{color:var(--muted)}

    /* Diagnostic area */
    pre{margin:0; font:12px/1.35 ui-monospace, SFMono-Regular, Menlo, Consolas, "Liberation Mono", monospace; color:#c4ccd8}
    .green{color:var(--ok)} .yellow{color:var(--warn)} .red{color:var(--err)}
    .badge{display:inline-block; padding:2px 8px; border-radius:999px; background:#202a39; margin-left:8px; font-size:12px}
    .meter{
      height:8px; border-radius:999px; background:#1b2533; overflow:hidden;
    }
    .bar{height:100%; width:0%; background:linear-gradient(90deg,#3b82f6,#22c55e); transition:width .08s linear}
    .inline{display:flex; align-items:center; gap:10px}
  </style>
</head>
<body>
  <div class="row" style="gap:18px; width:100%; max-width:1200px; margin-inline:auto">
    <section class="panel">
      <h1>EmotiKnow — Emma (Voice Companion)
        <span id="status" class="badge">idle</span>
      </h1>

      <div class="canvas">
        <div class="inner" id="stage">
          <!-- Your portrait -->
          <img id="portrait" src="/m.png" alt="Emma" />
          <!-- Lip overlay -->
          <img id="mouth" alt="mouth" />
        </div>
      </div>

      <div class="controls" style="margin-top:14px">
        <div class="btns">
          <button id="start" class="primary">Start</button>
          <button id="hang">Hang Up</button>
          <button id="test">Test speaker</button>
          <div class="inline" style="margin-left:auto">
            <small class="hint">VU</small>
            <div class="meter" style="width:160px"><div id="vu" class="bar"></div></div>
          </div>
        </div>

        <div class="row2">
          <label>
            Target width
            <input id="widthRange" type="range" min="120" max="720" value="260" />
          </label>
          <label>
            Scale (%)
            <input id="scaleRange" type="range" min="70" max="160" value="100" />
          </label>
        </div>

        <div class="row3">
          <label>
            Speed (ms per frame)
            <input id="spd" type="range" min="160" max="420" value="300" step="10" />
          </label>
          <label>
            Smoothing
            <input id="smt" type="range" min="80" max="98" value="92" step="1" />
          </label>
          <label>
            Gate (silence)
            <input id="gt" type="range" min="6" max="22" value="12" step="1" />
          </label>
        </div>

        <small class="hint">
          Tip: Click <b>Emma’s real mouth once</b> to anchor the overlay. The position & sizing are saved per browser.
        </small>
      </div>
    </section>

    <aside class="panel">
      <div class="inline" style="justify-content:space-between">
        <strong>Diagnostics</strong>
        <span id="model" class="badge">model: gpt-4o-mini-realtime-preview</span>
      </div>
      <pre id="log" style="margin-top:10px; max-height:68vh; overflow:auto"></pre>
    </aside>
  </div>

  <script>
  /* ===========================================================
     Assets & simple logger
  =========================================================== */
  const LOG = (s) => {
    const el = document.getElementById('log');
    const at = new Date().toTimeString().slice(0,8);
    el.textContent += `[${at}] ${s}\n`;
    el.scrollTop = el.scrollHeight;
  };

  const portrait = document.getElementById('portrait');
  const mouth = document.getElementById('mouth');
  const statusBadge = document.getElementById('status');
  const vuBar = document.getElementById('vu');

  const frames = ["m","i","say","o","u","f","g","l","p"];   // map -> /mouth/<name>.png
  const mouthImgs = {}; // key -> preloaded Image
  let allReady = false;

  function preloadMouth() {
    let done = 0;
    frames.forEach(k=>{
      const img = new Image();
      img.onload = () => { done++; if (done === frames.length) { allReady = true; LOG(`[frames] loaded ${done}/${frames.length}`); } };
      img.onerror = () => LOG(`[ERROR] failed to load /mouth/${k}.png`);
      img.src = `/mouth/${k}.png`;
      mouthImgs[k] = img;
    });
  }
  preloadMouth();

  /* ===========================================================
     Anchor (where the overlay sits on Emma’s face)
  =========================================================== */
  const anchorStoreKey = 'emma-mouth-anchor-v1';
  let anchor = JSON.parse(localStorage.getItem(anchorStoreKey) || 'null'); // {x:0..1, y:0..1}
  let targetWidth = +localStorage.getItem('emma-mouth-width') || 260;
  let targetScale = +localStorage.getItem('emma-mouth-scale') || 100;

  const widthRange = document.getElementById('widthRange');
  const scaleRange = document.getElementById('scaleRange');
  widthRange.value = targetWidth;
  scaleRange.value = targetScale;

  function applyOverlayLayout(){
    if (!anchor) return;
    const r = portrait.getBoundingClientRect();
    const x = r.left + r.width * anchor.x;
    const y = r.top  + r.height* anchor.y;
    mouth.style.width = `${targetWidth}px`;
    mouth.style.left = `${x}px`;
    mouth.style.top  = `${y}px`;
    mouth.style.transform = `translate(-50%,-50%) scale(${targetScale/100})`;
  }

  // Click once on the portrait to place mouth overlay
  portrait.addEventListener('click', (ev)=>{
    const r = portrait.getBoundingClientRect();
    const x = (ev.clientX - r.left) / r.width;
    const y = (ev.clientY - r.top ) / r.height;
    anchor = {x: +x.toFixed(3), y: +y.toFixed(3)};
    localStorage.setItem(anchorStoreKey, JSON.stringify(anchor));
    LOG(`[anchor] saved x=${anchor.x.toFixed(3)}, y=${anchor.y.toFixed(3)}`);
    applyOverlayLayout();
  });

  window.addEventListener('resize', applyOverlayLayout);
  widthRange.addEventListener('input', e=>{
    targetWidth = +e.target.value;
    localStorage.setItem('emma-mouth-width', targetWidth);
    applyOverlayLayout();
  });
  scaleRange.addEventListener('input', e=>{
    targetScale = +e.target.value;
    localStorage.setItem('emma-mouth-scale', targetScale);
    applyOverlayLayout();
  });

  /* ===========================================================
     Mouth frame setter (kept tiny & fast)
  =========================================================== */
  function updateMouthFrame(key){
    if (!allReady) return;
    const img = mouthImgs[key] || mouthImgs["m"];
    if (!img) return;
    mouth.src = img.src;
  }

  /* ===========================================================
     Lip driver (smooth, tunable)
  =========================================================== */
  // Default tunables (also exposed to sliders)
  window.FRAME_MS = 300;      // milliseconds between frame changes when talking
  window.SMOOTH   = 0.92;     // EMA smoothing for amplitude (0..0.99)
  window.GATE     = 0.12;     // anything below is treated as silence
  const HOLD_MS   = { say:140, o:160, u:160, m:220 };
  const TALK_ORDER = ["m","i","say","o","u","f","g","l","p"];

  // Slider wiring
  spd.oninput = () => window.FRAME_MS = +spd.value;
  smt.oninput = () => window.SMOOTH   = (+smt.value)/100;
  gt.oninput  = () => window.GATE     = (+gt.value)/100;

  let analyser, data, vuEMA = 0;
  let lastFrameAt = 0, currentIdx = 0, holdingUntil = 0, rafId;

  function vu() {
    if (!analyser) return 0;
    analyser.getByteTimeDomainData(data);
    let min=255, max=0;
    for (let i=0;i<data.length;i++){ const v=data[i]; if(v<min)min=v; if(v>max)max=v; }
    const amp = (max-min)/255;
    vuEMA = window.SMOOTH * vuEMA + (1-window.SMOOTH)*amp;
    return vuEMA;
  }
  function holdFor(key){ return HOLD_MS[key] ?? 0; }

  function lipTick(now = performance.now()){
    const level = vu();

    // Show VU bar
    vuBar.style.width = Math.round(level*100) + '%';

    const talking = level > window.GATE;

    if (!talking){
      updateMouthFrame("m");
      holdingUntil = 0;
      return;
    }
    if (holdingUntil && now < holdingUntil) return;
    if (now - lastFrameAt < window.FRAME_MS) return;

    currentIdx = (currentIdx + 1) % TALK_ORDER.length;
    const key = TALK_ORDER[currentIdx];
    updateMouthFrame(key);

    lastFrameAt = now;
    holdingUntil = now + holdFor(key);
  }

  function startLipLoop(){
    cancelAnimationFrame(rafId);
    const loop = ()=>{ lipTick(); rafId = requestAnimationFrame(loop); };
    rafId = requestAnimationFrame(loop);
  }

  async function initAnalyser(stream){
    const ctx = new (window.AudioContext||window.webkitAudioContext)();
    const src = ctx.createMediaStreamSource(stream);
    analyser = ctx.createAnalyser();
    analyser.fftSize = 2048;
    data = new Uint8Array(analyser.fftSize);
    src.connect(analyser);
    startLipLoop();
  }

  /* ===========================================================
     OpenAI Realtime (WebRTC) hookup
     - expects your Vercel function at /api/realtime-session
  =========================================================== */
  let pc, localStream, remoteAudio;

  async function startCall(){
    try{
      statusBadge.textContent = 'connecting';
      statusBadge.style.background = '#2a3547';
      LOG('[mic] requesting…');

      // 1) Microphone
      localStream = await navigator.mediaDevices.getUserMedia({ audio:true, video:false });
      LOG('[mic] granted.');
      await initAnalyser(localStream);

      // 2) RTCPeerConnection
      pc = new RTCPeerConnection();
      remoteAudio = document.createElement('audio');
      remoteAudio.autoplay = true;

      // Remote audio track
      pc.ontrack = (e)=>{ if (e.streams?.[0]) remoteAudio.srcObject = e.streams[0]; };

      // Send mic to AI + receive audio back
      localStream.getTracks().forEach(t=>pc.addTrack(t, localStream));
      pc.addTransceiver('audio',{direction:'recvonly'});

      // 3) Create local offer
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);

      // 4) Fetch ephemeral token from your API route
      LOG('[token] fetching…');
      const r = await fetch('/api/realtime-session', { method:'POST' });
      const { client_secret, model } = await r.json();
      document.getElementById('model').textContent = `model: ${model||'gpt-4o-mini-realtime-preview'}`;
      LOG('[token] ok.');

      // 5) Exchange SDP with OpenAI Realtime
      LOG('[sdp] exchanging via /api/realtime-session (POST)…');
      const resp = await fetch('https://api.openai.com/v1/realtime?model='+(model||'gpt-4o-mini-realtime-preview'), {
        method:'POST',
        headers:{
          'Authorization': 'Bearer ' + client_secret.value,
          'Content-Type': 'application/sdp'
        },
        body: offer.sdp
      });

      const answerSdp = await resp.text();
      if (!answerSdp?.startsWith('v=')){ LOG('[ERROR] [sdp] 201 v=0\n'+answerSdp); throw new Error('SDP answer missing v='); }
      await pc.setRemoteDescription({ type:'answer', sdp:answerSdp });

      statusBadge.textContent = 'live';
      statusBadge.style.background = '#11351f';
      LOG('[sdp] handshake complete.');

    }catch(err){
      statusBadge.textContent = 'error';
      statusBadge.style.background = '#3a1120';
      LOG('[ERROR] '+err.message);
    }
  }

  async function hangUp(){
    statusBadge.textContent = 'ended';
    statusBadge.style.background = '#3a2a11';
    try{
      if (pc) { pc.getSenders().forEach(s=>s.track && s.track.stop()); pc.close(); }
      if (localStream){ localStream.getTracks().forEach(t=>t.stop()); }
      cancelAnimationFrame(rafId);
      LOG('[call] ended.');
    }catch{}
  }

  async function testSpeaker(){
    try{
      // quick ping tone so you can verify device audio path
      const ctx = new (window.AudioContext||window.webkitAudioContext)();
      const o = ctx.createOscillator(); const g = ctx.createGain();
      o.type='sine'; o.frequency.value=880; g.gain.value=0.02;
      o.connect(g).connect(ctx.destination);
      o.start(); setTimeout(()=>{ o.stop(); ctx.close(); }, 300);
      LOG('[speaker] test ping.');
    }catch(e){ LOG('[ERROR] speaker test: '+e.message); }
  }

  // Buttons
  document.getElementById('start').addEventListener('click', startCall);
  document.getElementById('hang').addEventListener('click', hangUp);
  document.getElementById('test').addEventListener('click', testSpeaker);

  // First paint
  updateMouthFrame('m');
  if (anchor) applyOverlayLayout();
  else LOG('Tip: Click Emma’s real mouth once to anchor overlay.');

  </script>
</body>
