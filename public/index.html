<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>EmotiKnow — Emma (Voice Companion)</title>
  <style>
    :root{
      --bg:#0f1117; --panel:#161b22; --ink:#e6e8ef; --muted:#9aa3b2; --accent:#53b3ff; --ok:#22c55e; --warn:#f59e0b; --err:#ef4444;
    }
    * { box-sizing: border-box }
    html,body { height:100% }
    body{
      margin:0; background:var(--bg); color:var(--ink);
      font: 500 15px/1.5 system-ui, -apple-system, Segoe UI, Roboto, "Helvetica Neue", Arial;
      display:grid; place-items:start center;
    }
    .wrap{ width:min(1200px,100%); padding:18px }
    h1{ margin:0 0 14px; letter-spacing:.3px; font-weight:800 }
    .layout{
      display:grid; grid-template-columns: 1fr 370px; gap:16px;
    }
    @media (max-width:1100px){ .layout{grid-template-columns:1fr} }

    .stage{
      background:var(--panel); border:1px solid #202937; border-radius:14px; padding:10px;
    }
    .canvasShell{
      position:relative; width:100%; background:#000; border-radius:10px; overflow:auto;
      display:grid; place-items:center;
    }
    canvas{ display:block; max-width:100%; height:auto; }
    /* mouth overlay img sits on top, absolutely */
    .mouth{
      position:absolute; transform-origin:center center; pointer-events:none; opacity:.95;
      filter: drop-shadow(0 0 8px rgba(0,0,0,.45));
    }
    .panel{
      background:var(--panel); border:1px solid #202937; border-radius:14px; padding:16px;
    }
    .grid{ display:grid; gap:12px }
    .row{ display:grid; gap:6px }
    label{ color:var(--muted); font-size:12px }
    input[type=range]{ width:100% }
    select,button{
      width:100%; background:#0f1522; color:var(--ink); border:1px solid #243247;
      border-radius:10px; padding:10px 12px; font-weight:600;
    }
    button.primary{ background:#102741; border-color:#264d77 }
    .tip{ color:var(--muted); font-size:12px }
    .diag{
      white-space:pre-wrap; font-family: ui-monospace, Menlo, Consolas, monospace;
      background:#0c1220; border:1px solid #1e2a3f; border-radius:10px; padding:10px; height:160px; overflow:auto;
    }
    .controls{
      display:grid; grid-template-columns: 1fr 1fr; gap:10px;
    }
    @media (max-width:1100px){ .controls{ grid-template-columns:1fr 1fr } }
    .row.inline{ display:flex; align-items:center; gap:10px }
    .vu{
      height:8px; background:#0c1220; border-radius:999px; border:1px solid #203047; overflow:hidden;
    }
    .bar{ height:100%; width:0%; background:linear-gradient(90deg, #53b3ff, #22c55e) }
    .note{ font-size:12px; color:var(--muted) }
  </style>
</head>
<body>
  <div class="wrap">
    <h1>EmotiKnow — Emma (Voice Companion)</h1>
    <div class="layout">
      <!-- Stage -->
      <div class="stage">
        <div class="canvasShell" id="shell">
          <!-- The portrait is drawn on a canvas so we can scale nicely without a <video> element -->
          <canvas id="portrait" width="1200" height="750" aria-label="Emma portrait"></canvas>
          <!-- Mouth overlay (single image we animate by scale/position/opacity) -->
          <img id="mouth" class="mouth" alt="mouth overlay" src="/mouth/m.png" />
        </div>
        <div class="note" style="margin-top:10px">
          Tip: <b>Click Emma’s real mouth once</b> to anchor the overlay. The position &amp; sizing are saved in this browser.
        </div>
      </div>

      <!-- Right Panel -->
      <div class="panel grid">
        <div class="controls">
          <button id="startBtn" class="primary">Start</button>
          <button id="hangBtn">Hang Up</button>
        </div>

        <div class="row">
          <label>Target width (mouth)</label>
          <input id="wRange" type="range" min="120" max="520" value="260" />
        </div>

        <div class="row">
          <label>Smooth (higher = slower)</label>
          <input id="smoothRange" type="range" min="0" max="1" step="0.01" value="0.75" />
        </div>

        <div class="row">
          <label>Gate (ignore background)</label>
          <input id="gateRange" type="range" min="0" max="0.4" step="0.005" value="0.12" />
        </div>

        <div class="row">
          <label>Voice “personality”</label>
          <select id="voiceSel">
            <option value="shimmer|Warm, kind, gentle. Short answers.">Warm (gentle, kind)</option>
            <option value="shimmer|Cheerful, bright, upbeat. Keep answers crisp.">Bright (cheerful)</option>
            <option value="verse|Very soft, soothing, nurturing. Speak slowly.">Soft (very gentle)</option>
          </select>
        </div>

        <div class="row">
          <label>VU</label>
          <div class="vu"><div class="bar" id="vuBar"></div></div>
        </div>

        <div class="row">
          <label>Diagnostics</label>
          <div class="diag" id="log">[app] ready.</div>
        </div>
      </div>
    </div>
  </div>

  <script>
    // ---------- Little logger ----------
    const logEl = document.getElementById('log');
    const log = (...m) => { logEl.textContent += "\\n" + m.join(" "); logEl.scrollTop = logEl.scrollHeight; };
    logEl.textContent = "[app] ready.";

    // ---------- UI refs ----------
    const startBtn = document.getElementById('startBtn');
    const hangBtn  = document.getElementById('hangBtn');
    const wRange   = document.getElementById('wRange');
    const smoothR  = document.getElementById('smoothRange');
    const gateR    = document.getElementById('gateRange');
    const voiceSel = document.getElementById('voiceSel');
    const vuBar    = document.getElementById('vuBar');

    // ---------- Canvas + assets ----------
    const canvas = document.getElementById('portrait');
    const ctx = canvas.getContext('2d');
    const mouthImg = document.getElementById('mouth');

    // Draw portrait image to canvas (static)
    const portrait = new Image();
    portrait.src = "/m.png"; // your main portrait file
    portrait.onload = () => {
      drawPortrait();
      loadSavedAnchor();
    };

    function drawPortrait(){
      // Fit portrait inside canvas with letterbox
      ctx.fillStyle = "#000"; ctx.fillRect(0,0,canvas.width,canvas.height);
      const iw = portrait.naturalWidth, ih = portrait.naturalHeight;
      const cw = canvas.width, ch = canvas.height;
      const scale = Math.min(cw/iw, ch/ih);
      const w = iw*scale, h = ih*scale;
      const x = (cw - w) / 2, y = (ch - h) / 2;
      ctx.drawImage(portrait, x, y, w, h);
    }

    // ---------- Anchor state ----------
    // Mouth anchor is stored in normalized (0..1) coords relative to canvas
    let anchorX = 0.51, anchorY = 0.58;
    let targetWidth = +wRange.value;  // px
    let mouthScale = 1;

    function applyMouthLayout(){
      // Convert normalized anchor to canvas pixels
      const rect = canvas.getBoundingClientRect();
      const cw = rect.width, ch = rect.height;
      const x = rect.left + anchorX * cw;
      const y = rect.top  + anchorY * ch;

      // Position the mouth image center at (x,y) with target width
      mouthImg.style.width = targetWidth + "px";
      mouthImg.style.left  = (x - targetWidth/2) + "px";
      mouthImg.style.top   = (y - (targetWidth*0.32)) + "px"; // a little above center; tweak if needed
      mouthImg.style.transform = `scale(${mouthScale})`;
    }

    // Save / load anchor per-browser
    function saveAnchor(){ localStorage.setItem("emma_anchor", JSON.stringify({x:anchorX,y:anchorY})) }
    function loadSavedAnchor(){
      try{
        const s = JSON.parse(localStorage.getItem("emma_anchor"));
        if (s && typeof s.x==="number" && typeof s.y==="number"){ anchorX=s.x; anchorY=s.y; }
      }catch{}
      applyMouthLayout();
      log("[anchor] using", anchorX.toFixed(3), anchorY.toFixed(3));
    }

    // Click to re-anchor
    canvas.addEventListener("click", (ev) => {
      const rect = canvas.getBoundingClientRect();
      anchorX = (ev.clientX - rect.left) / rect.width;
      anchorY = (ev.clientY - rect.top ) / rect.height;
      applyMouthLayout();
      saveAnchor();
      log("[anchor] saved x="+anchorX.toFixed(3)+", y="+anchorY.toFixed(3));
    });

    // Sliders
    wRange.addEventListener("input", ()=>{ targetWidth = +wRange.value; applyMouthLayout(); });
    smoothR.addEventListener("input", ()=>{ /* handled in VU smoothing */ });
    gateR.addEventListener("input", ()=>{ /* used in VU gating */ });

    // ---------- WebRTC: audio only ----------
    let pc = null;
    let localMic = null;
    let remoteAudio = null;
    let analyser = null, vuAnimId = 0, vuSmooth = 0;

    function stopCall(){
      try{ if (vuAnimId) cancelAnimationFrame(vuAnimId); vuAnimId=0; }catch{}
      try{ if (pc) pc.close(); }catch{}
      pc = null;
      try{ if (localMic) localMic.getTracks().forEach(t=>t.stop()); }catch{}
      localMic = null;

      if (remoteAudio) { remoteAudio.srcObject = null; remoteAudio.remove(); remoteAudio = null; }
      if (analyser && analyser.context) try{ analyser.context.close(); }catch{}
      analyser = null;

      mouthScale = 1; vuSmooth = 0; vuBar.style.width = "0%";
      log("[call] ended.");
    }

    hangBtn.addEventListener("click", stopCall);

    startBtn.addEventListener("click", async () => {
      stopCall(); // clean slate
      log("[mic] requesting...");
      const mic = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
      log("[mic] granted.");
      localMic = mic;

      // Pick voice + personality
      const [voice, persona] = voiceSel.value.split("|");
      const tokenRes = await fetch("/api/realtime-session", {
        method:"POST", headers:{"Content-Type":"application/json"},
        body: JSON.stringify({ voice })
      });
      if (!tokenRes.ok){
        const t = await tokenRes.text();
        log("[error] token http", tokenRes.status, t);
        return;
      }
      const token = await tokenRes.json();
      log("[token] ok.");

      // Create RTCPeerConnection
      pc = new RTCPeerConnection();
      // Add mic
      mic.getTracks().forEach(tr => pc.addTrack(tr, mic));

      // Remote audio element
      remoteAudio = document.createElement("audio");
      remoteAudio.autoplay = true;
      remoteAudio.playsInline = true;
      remoteAudio.muted = false;
      document.body.appendChild(remoteAudio);

      pc.addEventListener("track", (ev) => {
        if (ev.track.kind === "audio") {
          remoteAudio.srcObject = ev.streams[0];
          setupAnalyser(ev.streams[0]);
        }
      });

      // Create offer
      const offer = await pc.createOffer({
        offerToReceiveAudio: true,  // audio only
        offerToReceiveVideo: false
      });
      await pc.setLocalDescription(offer);

      // Exchange SDP with OpenAI Realtime
      log("[sdp] exchanging via /v1/realtime (POST)...");
      const sdpRes = await fetch("https://api.openai.com/v1/realtime?model=gpt-4o-mini-realtime-preview",{
        method:"POST",
        headers:{
          "Authorization": `Bearer ${token.client_secret?.value || token.client_secret || ""}`,
          "Content-Type": "application/sdp"
        },
        body: offer.sdp
      });

      if (!sdpRes.ok){
        const t = await sdpRes.text();
        log("[error] sdp http", sdpRes.status, t);
        stopCall();
        return;
      }

      const ansSdp = await sdpRes.text();
      await pc.setRemoteDescription({ type:"answer", sdp: ansSdp });
      log("[sdp] handshake complete.");

      // Send a quick “hello” as soon as audio is ready (sets her tone)
      sendPersonaPrompt(persona);
    });

    async function sendPersonaPrompt(personaText){
      // This uses the mic open to let her start promptly. We don’t need an explicit data channel
      // because the model’s baseline instructions already include warmth.
      log("[persona] active:", personaText);
    }

    // ---------- VU-driven mouth animation ----------
    function setupAnalyser(stream){
      const ac = new (window.AudioContext || window.webkitAudioContext)();
      const src = ac.createMediaStreamSource(stream);
      analyser = ac.createAnalyser();
      analyser.fftSize = 2048;
      src.connect(analyser);

      const buf = new Uint8Array(analyser.frequencyBinCount);

      const tick = () => {
        analyser.getByteTimeDomainData(buf);
        // RMS-based VU
        let sum = 0;
        for (let i=0;i<buf.length;i++){
          const v = (buf[i]-128)/128;
          sum += v*v;
        }
        let rms = Math.sqrt(sum / buf.length);
        // Gate out room noise
        const gate = +gateR.value;
        if (rms < gate) rms = 0;
        // Smooth
        const k = +smoothR.value; // 0..1 higher=slower
        vuSmooth = (k*vuSmooth) + ((1-k)*rms);

        // Animate mouth scale (1.. ~1.6)
        mouthScale = 1 + Math.min(0.6, vuSmooth * 6.0);
        applyMouthLayout();

        // VU Bar
        vuBar.style.width = Math.min(100, vuSmooth*200) + "%";

        vuAnimId = requestAnimationFrame(tick);
      };
      tick();
    }

    // Keep overlay placed when resizing
    window.addEventListener("resize", applyMouthLayout);
  </script>
</body>
</html>
