<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta
    name="viewport"
    content="width=device-width, initial-scale=1, viewport-fit=cover" />
  <title>EmotiKnow — Emma (Voice Companion)</title>
  <style>
    :root{
      --bg:#0f1117;
      --panel:#151b23;
      --ink:#e6e8ef;
      --muted:#9aa3b2;
      --accent:#8ab4ff;
      --ok:#22c55e;
      --warn:#f59e0b;
      --err:#ef4444;
    }
    *{box-sizing:border-box}
    html,body{height:100%}
    body{
      margin:0;
      background:var(--bg);
      color:var(--ink);
      font:500 15px/1.45 ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, "Helvetica Neue", Arial;
      display:flex; justify-content:center; align-items:flex-start;
    }
    .wrap{width:min(1200px,100%); padding:16px}
    h1{font-weight:800; letter-spacing:.2px; margin:4px 0 14px; font-size:clamp(20px, 3vw, 28px)}
    .row{display:grid; grid-template-columns:1fr 360px; gap:16px}
    @media (max-width:1000px){ .row{grid-template-columns:1fr} }

    .stage{
      background:#000; border-radius:16px; padding:14px;
      border:1px solid #202937; box-shadow:0 0 0 1px #0c1016 inset;
      display:flex; justify-content:center; align-items:center; min-height:520px;
      overflow:auto;
    }
    .panel{
      background:var(--panel); border:1px solid #202937; border-radius:16px; padding:14px;
    }

    .portraitBox{
      position:relative; width:min(900px, 100%); aspect-ratio:16/9;
      background:#000; overflow:hidden; border-radius:12px;
      margin:auto;
      display:flex; justify-content:center; align-items:center;
    }
    .portraitBox img.portrait{
      width:100%; height:100%; object-fit:contain; user-select:none; pointer-events:none;
      display:block;
    }
    /* Mouth overlay */
    #mouth{
      position:absolute; left:50%; top:50%;
      transform:translate(-50%,-50%) scale(1);
      transform-origin:center center;
      width:240px; opacity:.0; transition:opacity .18s ease;
      will-change:transform, left, top, opacity;
      pointer-events:none;
    }
    .tip{color:var(--muted); font-size:13px}
    .controls h3{margin:8px 0 10px; font-size:15px}
    .controls .row2{display:grid; grid-template-columns:1fr 1fr; gap:10px}
    .btn{
      display:inline-flex; align-items:center; justify-content:center; gap:8px;
      height:40px; padding:0 14px; border-radius:10px; border:1px solid #263042;
      background:#10151d; color:var(--ink); cursor:pointer; user-select:none;
      font-weight:700; letter-spacing:.2px;
    }
    .btn:disabled{opacity:.5; cursor:not-allowed}
    .btn.primary{background:#0f1c2d; border-color:#1f2a3f}
    .slider{width:100%}
    select, .select{
      width:100%; height:40px; border-radius:10px; border:1px solid #263042; background:#10151d; color:var(--ink);
      padding:0 10px; font-weight:600;
    }
    .vu{
      height:6px; border-radius:4px; background:#0f1420; border:1px solid #1b2232; overflow:hidden;
    }
    .vu > i{display:block; height:100%; width:0%; background:linear-gradient(90deg, #58d68d, #8ab4ff); transition:width .06s linear}
    pre.log{
      background:#0f1420; color:#c6d0e4; border:1px solid #1b2232; border-radius:10px; padding:10px; max-height:240px; overflow:auto;
      font-size:12px; line-height:1.5; white-space:pre-wrap; word-break:break-word;
    }
    .kbd{font:600 12px ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; color:#cfe1ff}
    a{color:var(--accent); text-decoration:none}
  </style>
</head>
<body>
  <div class="wrap">
    <h1>EmotiKnow — Emma (Voice Companion)</h1>

    <div class="row">
      <!-- STAGE -->
      <div class="stage">
        <div class="portraitBox" id="box">
          <!-- Your background portrait (kept as /m.png) -->
          <img class="portrait" id="portrait" src="/m.png" alt="Emma portrait" />

          <!-- The single mouth overlay image (we use one asset, scaled by VU) -->
          <img id="mouth" src="/mouth/m.png" alt="mouth overlay" />
        </div>
      </div>

      <!-- CONTROLS -->
      <div class="panel controls">
        <div class="row2" style="margin-bottom:10px">
          <button id="startBtn" class="btn primary">Start</button>
          <button id="hangBtn" class="btn">Hang Up</button>
        </div>

        <h3>Target width (mouth)</h3>
        <input id="wSlider" class="slider" type="range" min="120" max="640" value="260" />
        <div class="tip" style="margin-top:6px">Click Emma’s <span class="kbd">real mouth</span> once to anchor the overlay. The position &amp; sizing are saved per browser.</div>

        <h3 style="margin-top:16px">Smooth (higher = slower)</h3>
        <input id="smoothSlider" class="slider" type="range" min="0" max="100" value="70" />

        <h3 style="margin-top:16px">Gate (ignore background)</h3>
        <input id="gateSlider" class="slider" type="range" min="0" max="100" value="12" />

        <h3 style="margin-top:16px">Voice “personality”</h3>
        <select id="voiceSel">
          <!-- Only female-friendly presets here -->
          <option value="warm" selected>Warm (gentle, kind)</option>
          <option value="bright">Shimmer (bright)</option>
        </select>

        <h3 style="margin-top:16px; margin-bottom:6px">VU</h3>
        <div class="vu"><i id="vuBar"></i></div>

        <h3 style="margin-top:16px">Diagnostics</h3>
        <pre id="log" class="log">[app] ready.</pre>
      </div>
    </div>
  </div>

  <script>
    // -------------- Utilities --------------
    const $ = sel => document.querySelector(sel);
    const log = (...a) => {
      const el = $("#log");
      el.textContent += "\\n" + a.join(" ");
      el.scrollTop = el.scrollHeight;
      console.log(...a);
    };

    // -------------- DOM refs --------------
    const box = $("#box");
    const mouth = $("#mouth");
    const portrait = $("#portrait");
    const startBtn = $("#startBtn");
    const hangBtn = $("#hangBtn");
    const wSlider = $("#wSlider");
    const smoothSlider = $("#smoothSlider");
    const gateSlider = $("#gateSlider");
    const voiceSel = $("#voiceSel");
    const vuBar = $("#vuBar");

    // -------------- Anchor (mouth position) --------------
    // Saved as normalized x/y (0..1 of box).
    function loadAnchor() {
      try {
        const s = localStorage.getItem("emma_anchor");
        return s ? JSON.parse(s) : { x: 0.51, y: 0.58 };
      } catch { return { x: 0.51, y: 0.58 }; }
    }
    function saveAnchor(a) {
      localStorage.setItem("emma_anchor", JSON.stringify(a));
    }
    let anchor = loadAnchor();

    function applyMouthTransform(scaleOpen=1) {
      const rect = box.getBoundingClientRect();
      const xpx = rect.width * anchor.x;
      const ypx = rect.height * anchor.y;
      const targetW = parseInt(wSlider.value, 10);
      mouth.style.width = `${targetW}px`;
      mouth.style.left = `${xpx}px`;
      mouth.style.top = `${ypx}px`;
      mouth.style.transform = `translate(-50%,-50%) scale(${scaleOpen})`;
    }
    applyMouthTransform(1);

    // Click to re-anchor
    box.addEventListener("click", (e) => {
      // Ignore clicks on the control column’s scrollbar etc., only inside box:
      const r = box.getBoundingClientRect();
      const x = (e.clientX - r.left) / r.width;
      const y = (e.clientY - r.top) / r.height;
      anchor = { x: Math.max(0, Math.min(1, x)), y: Math.max(0, Math.min(1, y)) };
      saveAnchor(anchor);
      log("[anchor] saved x=" + anchor.x.toFixed(3) + ", y=" + anchor.y.toFixed(3));
      applyMouthTransform(1);
    });

    // Resize + slider updates
    window.addEventListener("resize", () => applyMouthTransform(openScale));
    wSlider.addEventListener("input", () => applyMouthTransform(openScale));

    // -------------- WebRTC (Realtime) --------------
    let pc = null;
    let localStream = null;
    let remoteStream = null;
    let remoteAudioEl = null;
    let rafId = 0;

    // Audio analysis for **remote** stream (so the mouth moves when Emma talks).
    let analyser = null, dataArr = null;
    let openScale = 1; // current visual scale
    let momentum = 0;  // smoothing integrator

    function stopCall() {
      if (pc) {
        pc.ontrack = null;
        try { pc.close(); } catch {}
        pc = null;
      }
      if (localStream) {
        localStream.getTracks().forEach(t => t.stop());
        localStream = null;
      }
      if (remoteAudioEl) {
        try { remoteAudioEl.srcObject = null; } catch {}
        remoteAudioEl.remove();
        remoteAudioEl = null;
      }
      cancelAnimationFrame(rafId);
      rafId = 0;
      mouth.style.opacity = "0"; // hide mouth overlay when idle
      vuBar.style.width = "0%";
      log("[call] ended.");
      startBtn.disabled = false;
      hangBtn.disabled = true;
    }

    async function startCall() {
      try {
        startBtn.disabled = true;
        hangBtn.disabled = false;

        // 1) Mic permission (needed for Realtime)
        log("[mic] requesting…");
        localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        log("[mic] granted.");

        // 2) Build RTCPeerConnection
        pc = new RTCPeerConnection();
        remoteAudioEl = document.createElement("audio");
        remoteAudioEl.autoplay = true;
        remoteAudioEl.playsInline = true;
        document.body.appendChild(remoteAudioEl);

        // Local -> PC
        localStream.getTracks().forEach(t => pc.addTrack(t, localStream));

        // Remote <- PC
        remoteStream = new MediaStream();
        pc.ontrack = (event) => {
          if (event.track.kind === "audio") {
            remoteStream.addTrack(event.track);
            remoteAudioEl.srcObject = remoteStream;
            setupRemoteAnalyser(remoteStream);
            mouth.style.opacity = "1"; // show mouth overlay now that audio can arrive
          }
        };

        // 3) Create offer SDP
        const offer = await pc.createOffer({
          offerToReceiveAudio: true,
          offerToReceiveVideo: false
        });
        await pc.setLocalDescription(offer);

        // 4) Get a short-lived session token from our server
        const chosen = voiceSel.value; // "warm" or "bright"
        const voiceForApi = (chosen === "bright") ? "shimmer" : "shimmer"; // both map to shimmer voice; timbre comes from instructions below
        log("[token] fetching…");
        const tokenRes = await fetch("/api/realtime-session", { method: "POST" });
        if (!tokenRes.ok) {
          const t = await tokenRes.text();
          throw new Error(`token http ${tokenRes.status} \\n${t}`);
        }
        const token = await tokenRes.json();
        log("[token] ok.");

        // 5) Exchange SDP directly with OpenAI
        const realtimeURL = `https://api.openai.com/v1/realtime?model=${encodeURIComponent(token.model)}`;
        const answerRes = await fetch(realtimeURL, {
          method: "POST",
          headers: {
            "Authorization": `Bearer ${token.client_secret?.value}`,
            "Content-Type": "application/sdp",
            "OpenAI-Beta": "realtime=v1"
          },
          body: offer.sdp
        });

        if (!answerRes.ok) {
          const t = await answerRes.text();
          throw new Error(`[sdp] answer failed: ${answerRes.status}\\n${t}`);
        }

        const answerSDP = await answerRes.text();
        await pc.setRemoteDescription({ type: "answer", sdp: answerSDP });
        log("[sdp] handshake complete.");

        // Send a gentle “personality” instruction once the peer is connected.
        // We do this over a data channel named "oai-events" if available; if not,
        // the model will still be friendly by default.
        const dc = pc.createDataChannel("oai-events");
        dc.onopen = () => {
          const personality = (voiceSel.value === "bright")
            ? "Be upbeat, encouraging, and friendly. Keep replies concise and positive. Speak as a kind young woman."
            : "Be warm, gentle, and caring. Use encouragement, listen actively, and keep replies natural. Speak as a kind young woman.";

          const msg = {
            type: "response.create",
            response: {
              instructions: personality
            }
          };
          try { dc.send(JSON.stringify(msg)); } catch {}
        };

      } catch (err) {
        log("[error] " + String(err));
        stopCall();
      }
    }

    function setupRemoteAnalyser(stream) {
      const ctx = new (window.AudioContext || window.webkitAudioContext)();
      const src = ctx.createMediaStreamSource(stream);
      analyser = ctx.createAnalyser();
      analyser.fftSize = 1024;
      dataArr = new Uint8Array(analyser.frequencyBinCount);
      src.connect(analyser);

      // animation loop
      const loop = () => {
        analyser.getByteTimeDomainData(dataArr);

        // Compute a simple RMS “loudness”
        let sum=0;
        for (let i=0;i<dataArr.length;i++){
          const v = (dataArr[i] - 128) / 128; // -1..+1
          sum += v*v;
        }
        const rms = Math.sqrt(sum / dataArr.length); // 0..~0.7
        const gate = parseInt(gateSlider.value,10) / 100; // 0..1
        const sm = parseInt(smoothSlider.value,10) / 100; // 0..1

        // Gate out background; map to 1..1.25 scale (subtle lip movement)
        const active = Math.max(0, rms - gate);
        const targetOpen = 1 + Math.min(0.30, active * 1.8); // cap opening
        // Smooth toward target
        momentum = momentum * sm + targetOpen * (1 - sm);
        openScale = momentum;

        vuBar.style.width = Math.min(100, Math.max(0, active*300)) + "%";
        applyMouthTransform(openScale);

        rafId = requestAnimationFrame(loop);
      };
      cancelAnimationFrame(rafId);
      rafId = requestAnimationFrame(loop);
    }

    // -------------- Wire up buttons/sliders --------------
    startBtn.addEventListener("click", startCall);
    hangBtn.addEventListener("click", stopCall);

    // Initialize UI
    hangBtn.disabled = true;
    mouth.style.opacity = "0.0";
    applyMouthTransform(1);
    log("[frames] loaded 9/9 (single overlay mode)");

  </script>
</body>
</html>
