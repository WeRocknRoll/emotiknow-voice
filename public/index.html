<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>EmotiKnow — Emma (Voice Companion)</title>
<style>
  :root{
    --bg:#0f1117; --panel:#151b23; --ink:#e6e8ef; --muted:#9aa3b2; --accent:#8ab4ff;
    --accent-2:#4cc9f0;
  }
  * { box-sizing:border-box }
  html, body { height:100%; }
  body{
    margin:0; background:var(--bg); color:var(--ink);
    font:500 15px/1.45 system-ui, -apple-system, Segoe UI, Roboto, "Helvetica Neue", Arial;
    display:flex; justify-content:center;
  }
  .wrap{ width:min(1100px,100%); padding:18px; }
  h1{ font-weight:800; letter-spacing:.2px; margin:6px 0 14px; }
  .row{ display:grid; grid-template-columns: 1fr 360px; gap:18px; }
  @media (max-width:1024px){ .row{ grid-template-columns:1fr } }
  .panel{
    background:var(--panel); border:1px solid #2a2f39; border-radius:14px; padding:14px;
  }
  .stage{
    display:grid; place-items:center; background:#0b0e14; border-radius:10px; overflow:hidden;
    min-height:520px;
  }
  /* Keep portrait responsive on smaller screens */
  .portrait{
    width:min(860px, 95%); max-width:860px; position:relative; user-select:none;
  }
  .portrait img{ display:block; width:100%; height:auto; }
  /* MOUTH overlay (we draw frames here and move by JS) */
  #mouth{
    position:absolute; left:50%; top:50%;
    transform:translate(-50%,-50%); pointer-events:none;
    width:240px; /* initial, user slider can change */
    image-rendering:auto;
  }

  /* Right control panel */
  .controls label{ display:block; font-size:12px; color:var(--muted); margin:14px 0 6px; }
  input[type=range]{ width:100% }
  .btn{
    display:inline-flex; align-items:center; justify-content:center;
    padding:10px 14px; border-radius:10px; font-weight:700; cursor:pointer;
    background:#1f2630; border:1px solid #2e3643; color:var(--ink);
  }
  .btn.primary{ background:#1b2838; border-color:#2a3a4f; }
  .btn.primary:hover{ outline:2px solid #2d4360 }
  .btn:disabled{ opacity:.5; cursor:not-allowed }

  /* Hide the tiny preview video completely */
  video#speakerPreview { display:none !important; }

  /* Diagnostics */
  pre{
    margin:8px 0 0; white-space:pre-wrap; background:#0b0f16; padding:10px; border-radius:8px;
    color:#aab3c2; max-height:220px; overflow:auto; border:1px solid #222936;
  }
</style>
</head>
<body>
<div class="wrap">
  <h1>EmotiKnow — Emma (Voice Companion)</h1>
  <div class="row">
    <div class="panel">
      <div class="stage">
        <div class="portrait" id="portrait">
          <!-- Your 1920x1200 image (already uploaded as /m.png) -->
          <img id="base" src="/m.png" alt="Emma" draggable="false" />
          <!-- mouth frames overlay -->
          <img id="mouth" src="/mouth/p.png" alt="mouth" draggable="false" />
        </div>
      </div>
    </div>

    <div class="panel controls">
      <div style="display:flex; gap:10px; margin-bottom:6px;">
        <button id="startBtn" class="btn primary" style="flex:1">Start</button>
        <button id="hangBtn"  class="btn" style="flex:1">Hang Up</button>
      </div>

      <label>Target width (mouth)</label>
      <input id="mouthWidth" type="range" min="120" max="520" value="260" />

      <label>Smooth (higher = slower)</label>
      <input id="smooth" type="range" min="0" max="1" step="0.01" value="0.80" />

      <label>Gate (ignore background)</label>
      <input id="gate" type="range" min="0" max="0.4" step="0.01" value="0.12" />

      <label style="margin-top:14px;">Voice “personality”</label>
      <select id="personality" class="btn" style="width:100%;">
        <option value="shimmer">Shimmer (bright)</option>
        <option value="ballad">Ballad (warm)</option>
      </select>

      <label style="margin-top:14px;">Diagnostics</label>
      <pre id="diag">[app] ready.</pre>
    </div>
  </div>
</div>

<!-- Hidden speaker video (kept for autoplay-unblock tests but hidden by CSS) -->
<video id="speakerPreview" playsinline></video>

<script>
(async function(){
  const diag = (m) => {
    const el = document.getElementById('diag');
    el.textContent += "\\n" + m;
    el.scrollTop = el.scrollHeight;
  };

  // UI elements
  const startBtn = document.getElementById('startBtn');
  const hangBtn  = document.getElementById('hangBtn');
  const widthSlider  = document.getElementById('mouthWidth');
  const smoothSlider = document.getElementById('smooth');
  const gateSlider   = document.getElementById('gate');
  const personality  = document.getElementById('personality');

  // Portrait and mouth
  const portrait = document.getElementById('portrait');
  const mouthImg = document.getElementById('mouth');

  // Your 9 PNG frames in /public/mouth/ (lowercase filenames)
  const frames = ["f","p","g","i","l","o","u","say","m"];
  const mouthImgs = {};
  await Promise.all(frames.map(async f=>{
    const img = new Image();
    img.src = `/mouth/${f}.png`;
    await img.decode().catch(()=>{});
    mouthImgs[f]=img;
  }));
  diag("[frames] loaded 9/9");

  // A very small phoneme map from amplitude → typical mouth frame.
  // (You can refine later by phoneme events if you emit them.)
  function frameForVU(vu){
    if (vu < 0.02) return "m";       // closed
    if (vu < 0.06) return "l";
    if (vu < 0.10) return "i";
    if (vu < 0.16) return "f";
    if (vu < 0.22) return "g";
    if (vu < 0.30) return "o";
    if (vu < 0.40) return "u";
    if (vu < 0.55) return "p";
    return "say";
  }

  // Simple mouth overlay placement (center-ish). Click once to re-anchor to Emma's mouth.
  let mouthAnchor = { x: 0.50, y: 0.56 }; // normalized (0..1) within the portrait
  portrait.addEventListener('click', (e)=>{
    const r = portrait.getBoundingClientRect();
    mouthAnchor.x = (e.clientX - r.left) / r.width;
    mouthAnchor.y = (e.clientY - r.top)  / r.height;
    diag(`[anchor] saved x=${mouthAnchor.x.toFixed(3)}, y=${mouthAnchor.y.toFixed(3)}`);
    placeMouth();
  });

  function placeMouth(){
    const r = portrait.getBoundingClientRect();
    const px = Math.round(mouthAnchor.x * r.width);
    const py = Math.round(mouthAnchor.y * r.height);
    mouthImg.style.left = px + "px";
    mouthImg.style.top  = py + "px";
    mouthImg.style.transform = "translate(-50%,-50%)";
    mouthImg.style.width = widthSlider.value + "px";
  }
  placeMouth();

  widthSlider.oninput = placeMouth;

  // --- WebRTC wiring to your /api/realtime-session ---
  let pc, micStream, remoteStream, analyserRemote, analyserMic, rafId;
  let ac; // AudioContext

  async function start(){
    try{
      startBtn.disabled = true;
      diag("[mic] requesting…");
      micStream = await navigator.mediaDevices.getUserMedia({ audio:true });
      diag("[mic] granted.");

      ac = new (window.AudioContext || window.webkitAudioContext)();
      // Mic analyser (helps open/close while user speaks)
      const micSrc = ac.createMediaStreamSource(micStream);
      analyserMic = ac.createAnalyser(); analyserMic.fftSize = 2048;
      micSrc.connect(analyserMic);

      pc = new RTCPeerConnection();
      remoteStream = new MediaStream();
      pc.ontrack = (ev)=>{
        if (ev.streams && ev.streams[0]){
          // Feed to AudioContext to measure remote VU (lip sync to Emma’s voice)
          const remoteAudio = document.createElement("audio");
          remoteAudio.autoplay = true; // let it play
          remoteAudio.srcObject = ev.streams[0];

          const remoteNode = ac.createMediaStreamSource(ev.streams[0]);
          analyserRemote = ac.createAnalyser(); analyserRemote.fftSize = 2048;
          remoteNode.connect(analyserRemote);
        }
      };

      // Send mic upstream
      micStream.getTracks().forEach(t => pc.addTrack(t, micStream));

      // SDP
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);

      // Ask server for a session with faster VAD & your chosen voice
      const s = await fetch("/api/realtime-session", {
        method: "POST",
        headers: { "Content-Type":"application/json" },
        body: JSON.stringify({ voice: personality.value })
      });
      if (!s.ok){
        const t = await s.text();
        diag("[error] token http " + s.status + "\\n" + t);
        startBtn.disabled = false;
        return;
     
