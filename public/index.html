<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>EmotiKnow — Emma (Voice Companion)</title>
<style>
  :root{
    --bg:#0f1117; --panel:#151b23; --ink:#e6e8ef; --accent:#8ab4ff;
  }
  *{box-sizing:border-box}
  html,body{height:100%}
  body{
    margin:0; background:var(--bg); color:var(--ink);
    font:500 16px/1.45 system-ui, -apple-system, "Segoe UI", Roboto, Helvetica, Arial;
    display:grid; place-items:start center; padding:18px;
  }
  .wrap{width:min(1200px,100%); display:grid; gap:16px}
  h1{margin:0 0 4px 0; font-weight:800; letter-spacing:.3px}
  .row{display:grid; grid-template-columns: 1.1fr .9fr; gap:16px}
  @media (max-width:980px){ .row{grid-template-columns:1fr} }

  .panel{ background:var(--panel); border:1px solid #202937; border-radius:14px; padding:14px }
  .canvas{ position:relative; aspect-ratio: 16/10; background:#000; border-radius:8px; overflow:hidden }
  .portrait{
    position:absolute; inset:0; width:100%; height:100%; object-fit:contain;
    background:#000;
  }
  /* Mouth overlay image */
  #mouth {
    position:absolute;
    left:50%; top:50%;
    width:260px; /* target width, live-updated */
    transform: translate(-50%,-50%) scale(1);
    pointer-events:none;
    opacity:.95;
    filter: drop-shadow(0 0 5px rgba(0,0,0,.25));
  }

  /* Diagnostics box */
  pre { white-space:pre-wrap; font:500 13px/1.35 ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; }
  .controls label{ font-size:13px; opacity:.85 }
  .controls .row2{ display:grid; grid-template-columns: 1fr 1fr; gap:10px }
  .controls input[type="range"]{ width:100% }
  .controls select, .controls button{ width:100%; padding:10px 12px; border-radius:10px; border:1px solid #263041; background:#1c2431; color:#f1f5fe }
  .controls button{ cursor:pointer }
  .controls button.primary{ background:#2b66ff; border-color:#2b66ff }
  .controls .stack{ display:grid; gap:6px; margin-bottom:8px }
  .muted{ opacity:.7; font-size:12px }

  /* Hide the tiny <audio>/<video> element used only to unlock autoplay */
  #speaker { position:absolute; width:1px; height:1px; left:-9999px; top:-9999px; opacity:0 }
</style>
</head>
<body>
  <div class="wrap">
    <h1>EmotiKnow — Emma (Voice Companion)</h1>

    <div class="row">
      <div class="panel">
        <div id="canvas" class="canvas">
          <!-- Your portrait -->
          <img id="portrait" class="portrait" src="/m.png" alt="portrait" />

          <!-- Lips overlay (updates to f.png, p.png, …) -->
          <img id="mouth" alt="mouth" />

          <!-- hidden audio to unlock sound on first interaction -->
          <audio id="speaker"></audio>
        </div>

        <div class="controls" style="margin-top:10px">
          <div class="row2">
            <div class="stack">
              <button id="startBtn" class="primary">Start</button>
            </div>
            <div class="stack">
              <button id="hangupBtn">Hang Up</button>
            </div>
          </div>

          <div class="row2">
            <div class="stack">
              <label>Target width</label>
              <input id="widthSlider" type="range" min="60" max="700" value="260">
            </div>
            <div class="stack">
              <label>Scale 100 %</label>
              <input id="scaleSlider" type="range" min="50" max="200" value="100">
            </div>
          </div>

          <div class="row2">
            <div class="stack">
              <label>Sensitivity (how much she opens) 1.00</label>
              <input id="senseSlider" type="range" min="30" max="200" value="100">
            </div>
            <div class="stack">
              <label>Smooth (slower, warmer lips) 0.70</label>
              <input id="smoothSlider" type="range" min="0" max="100" value="70">
            </div>
          </div>

          <div class="row2">
            <div class="stack">
              <label>Gate (ignore background) 0.12</label>
              <input id="gateSlider" type="range" min="0" max="40" value="12">
            </div>
            <div class="stack">
              <label>Personality</label>
              <select id="voiceSelect">
                <option value="shimmer" selected>Shimmer (bright)</option>
                <option value="verse">Verse (warm)</option>
                <option value="alloy">Alloy (clear)</option>
              </select>
            </div>
          </div>

          <div class="muted">Tip: click Emma’s real mouth once to anchor the overlay. The position & sizing are saved per browser.</div>
        </div>
      </div>

      <div class="panel">
        <div style="display:flex;justify-content:space-between;align-items:center">
          <div class="muted">model: gpt-4o-mini-realtime-preview</div>
          <div id="vu" class="muted">VU: 0.00</div>
        </div>
        <pre id="log">[app] ready.</pre>
      </div>
    </div>
  </div>

<script>
(() => {
  const portrait   = document.getElementById('portrait');
  const mouthEl    = document.getElementById('mouth');
  const startBtn   = document.getElementById('startBtn');
  const hangupBtn  = document.getElementById('hangupBtn');
  const widthSl    = document.getElementById('widthSlider');
  const scaleSl    = document.getElementById('scaleSlider');
  const senseSl    = document.getElementById('senseSlider');
  const smoothSl   = document.getElementById('smoothSlider');
  const gateSl     = document.getElementById('gateSlider');
  const voiceSel   = document.getElementById('voiceSelect');
  const logEl      = document.getElementById('log');
  const vuEl       = document.getElementById('vu');
  const speaker    = document.getElementById('speaker');

  // Load mouth frames from /mouth/
  const frameNames = ["f","p","g","i","l","o","u","v","say"];
  const frames = {};
  let framesLoaded = 0;
  frameNames.forEach(n => {
    const img = new Image();
    img.onload = () => { framesLoaded++; if (framesLoaded === frameNames.length) log('[frames] loaded 9/9'); };
    img.onerror = () => log('[error] missing /mouth/'+n+'.png');
    img.src = '/mouth/'+n+'.png';
    frames[n] = img;
  });

  // Clicking the portrait once anchors lips to that pixel
  let anchor = { x: 0.5, y: 0.56 }; // default normalized on m.png (tune!)
  portrait.addEventListener('click', (e) => {
    const r = portrait.getBoundingClientRect();
    anchor.x = (e.clientX - r.left) / r.width;
    anchor.y = (e.clientY - r.top)  / r.height;
    localStorage.setItem('emma_anchor', JSON.stringify(anchor));
    log(`[anchor] saved x=${anchor.x.toFixed(3)}, y=${anchor.y.toFixed(3)}`);
    positionMouth();
  });

  // restore saved anchor
  try {
    const saved = localStorage.getItem('emma_anchor');
    if (saved) anchor = JSON.parse(saved);
  } catch {_}

  function log(t){ logEl.textContent += '\n' + t; logEl.scrollTop = logEl.scrollHeight; }
  function clamp(v, lo, hi){ return Math.max(lo, Math.min(hi, v)); }

  // position mouth according to anchor + sliders
  function positionMouth(){
    const r = portrait.getBoundingClientRect();
    const x = r.left + r.width  * anchor.x;
    const y = r.top  + r.height * anchor.y;
    mouthEl.style.left = (anchor.x*100) + '%';
    mouthEl.style.top  = (anchor.y*100) + '%';
    mouthEl.style.width = widthSl.value + 'px';
    mouthEl.style.transform = `translate(-50%,-50%) scale(${(scaleSl.value|0)/100})`;
  }
  positionMouth();

  // smoother lip motion (envelope follower)
  let lastEnv = 0;
  function smoothEnv(raw){
    const s = (smoothSl.value|0)/100; // 0..1
    lastEnv = lastEnv*(0.6 + 0.35*s) + raw*(0.4 - 0.35*s);
    return lastEnv;
  }

  // map envelope to frame name
  function envToFrame(env){
    // tunables
    const gate = (gateSl.value|0)/100;     // ignore below gate
    const sens = (senseSl.value|0)/100;    // how much she opens

    let v = clamp((env - gate) / Math.max(0.0001, 1 - gate), 0, 1);
    v = Math.pow(v, 0.8) * sens;           // sensitivity curve

    if (v < 0.05) return 'm';              // closed (use 'm' == your neutral? fallback to 'u' or 'f')
    if (v < 0.15) return 'f';
    if (v < 0.28) return 'i';
    if (v < 0.42) return 'l';
    if (v < 0.56) return 'e';              // not provided; map to 'say'
    if (v < 0.70) return 'say';
    if (v < 0.85) return 'o';
    return 'v';
  }

  // we’ll swap image by key
  function showFrame(key){
    // fallback mapping to your actual file names
    const map = { m:'u', e:'say' };
    const k = frames[key] ? key : (frames[map[key]] ? map[key] : 'u');
    mouthEl.src = '/mouth/' + k + '.png';
  }
  // initialize neutral:
  showFrame('u');

  // Realtime session
  let pc = null;
  let micStream = null;

  async function startCall(){
    try{
      // unlock audio on first click/tap
      speaker.src = "data:audio/mp3;base64,//uQZAAAAAAAAAAAAAAAAAAAA";
      await speaker.play().catch(()=>{});

      // 1) Get ephemeral client_secret from our backend
      log('[token] fetching…');
      const r = await fetch('/api/realtime-session', { method:'POST' });
      if (!r.ok) {
        const txt = await r.text();
        log(`[error] token http ${r.status}\n${txt}`);
        return;
      }
      const sess = await r.json();
      log('[token] ok.');

      // 2) WebRTC setup
      pc = new RTCPeerConnection();

      // get mic
      log('[mic] requesting…');
      micStream = await navigator.mediaDevices.getUserMedia({ audio:true });
      log('[mic] granted.');
      micStream.getTracks().forEach(t => pc.addTrack(t, micStream));

      // receive remote audio (Emma’s voice)
      const out = new Audio();
      out.autoplay = true;
      pc.ontrack = (ev) => {
        out.srcObject = ev.streams[0];
      };

      // 3) Create offer & set local
      const offer = await pc.createOffer({ offerToReceiveAudio:true });
      await pc.setLocalDescription(offer);

      // 4) Send SDP to OpenAI Realtime
      log('[sdp] exchanging via api/realtime-session (POST)…');
      const sdpRes = await fetch(`https://api.openai.com/v1/realtime?model=gpt-4o-mini-realtime-preview&voice=${encodeURIComponent(voiceSel.value)}`, {
        method: "POST",
        headers: {
          Authorization: `Bearer ${sess.client_secret?.value ?? ""}`,
          "Content-Type": "application/sdp"
        },
        body: offer.sdp
      });

      if (!sdpRes.ok) {
        const txt = await sdpRes.text();
        log(`[error] sdp ${sdpRes.status} v=0\n${txt}`);
        return;
      }

      const answer = { type:"answer", sdp: await sdpRes.text() };
      await pc.setRemoteDescription(answer);
      log('[sdp] handshake complete.');

      // 5) VU meter + mouth drive
      const ctx = new (window.AudioContext || window.webkitAudioContext)();
      const src = ctx.createMediaStreamSource(micStream);
      const analyser = ctx.createAnalyser();
      analyser.fftSize = 1024;
      src.connect(analyser);
      const buf = new Uint8Array(analyser.frequencyBinCount);

      function tick(){
        analyser.getByteTimeDomainData(buf);
        // basic peak/RMS
        let sum = 0;
        for (let i=0;i<buf.length;i++){
          const v = (buf[i]-128)/128;
          sum += v*v;
        }
        const rms = Math.sqrt(sum / buf.length);
        const env = smoothEnv(rms*3.2); // scale a bit
        vuEl.textContent = 'VU: ' + env.toFixed(2);

        showFrame(envToFrame(env));
        requestAnimationFrame(tick);
      }
      tick();

      // close handler
      pc.onconnectionstatechange = () => {
        if (pc.connectionState === "disconnected" || pc.connectionState === "failed" || pc.connectionState === "closed"){
          log('[call] ended.');
        }
      };
    }catch(err){
      log('[error] ' + (err?.message || String(err)));
    }
  }

  async function hangup(){
    try{
      if (pc) { pc.getSenders().forEach(s => { try{s.track?.stop()}catch{} }); pc.close(); }
      if (micStream) micStream.getTracks().forEach(t => t.stop());
    }catch{}
    pc = null; micStream = null;
    log('[call] ended.');
  }

  startBtn.addEventListener('click', startCall);
  hangupBtn.addEventListener('click', hangup);

  // sliders live update
  [widthSl, scaleSl, senseSl, smoothSl, gateSl].forEach(sl => sl.addEventListener('input', positionMouth));

  log('[app] ready.');
})();
</script>
</body>
</html>
