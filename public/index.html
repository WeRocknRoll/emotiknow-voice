<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>EmotiKnow — Emma (Voice Companion)</title>
<link rel="preconnect" href="https://fonts.googleapis.com" />
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet" />
<style>
  :root{
    --bg:#0b0f14; --panel:#121722; --panel-2:#0f1420; --text:#e9eef7;
    --muted:#9fb0c9; --accent:#7c9cff; --ok:#7ef7c9; --warn:#ffce6a;
    --rose:#ff6b81; /* lip color (base) */
  }
  *{box-sizing:border-box}
  html,body{height:100%}
  body{
    margin:0;background:radial-gradient(1200px 1200px at 80% -10%,#10182a 0%,var(--bg) 60%);
    color:var(--text); font-family:Inter,system-ui,Segoe UI,Roboto,Helvetica,Arial,sans-serif;
  }
  header{max-width:1200px;margin:28px auto 10px;padding:0 20px}
  h1{font-size: clamp(22px, 3.2vw, 34px); margin:0 0 6px}
  .sub{color:var(--muted);font-size:14px}

  .wrap{max-width:1200px;margin:12px auto 40px;padding:0 20px;display:grid;gap:18px;
        grid-template-columns:minmax(280px,1fr) minmax(320px,420px)}
  .card{
    background:linear-gradient(180deg, rgba(255,255,255,.04), transparent 60%) , var(--panel);
    border:1px solid rgba(255,255,255,.06); border-radius:18px; overflow:hidden;
    box-shadow:0 10px 40px rgba(0,0,0,.35);
  }
  .card h3{margin:0;padding:14px 16px;border-bottom:1px solid rgba(255,255,255,.06);font-size:14px;color:var(--muted)}
  .stage{position:relative;aspect-ratio:16/10;background:var(--panel-2);display:flex;align-items:center;justify-content:center}
  .portrait{max-width:100%;max-height:100%;display:block;user-select:none;-webkit-user-drag:none}
  #overlay{position:absolute; inset:0; pointer-events:none}

  .controls{display:flex;gap:10px;flex-wrap:wrap;align-items:center;padding:12px;border-top:1px solid rgba(255,255,255,.06)}
  button, select{
    background:#1b2332; color:var(--text); border:1px solid rgba(255,255,255,.10);
    border-radius:10px; padding:10px 14px; font-weight:600; cursor:pointer;
  }
  button.primary{background:var(--accent); border:none; color:#06122b}
  button.warn{background:#2a3142;color:#ffc97a;border-color:#4a4f63}
  button:disabled{opacity:.55;cursor:not-allowed}
  select{padding:9px 12px}
  .sliders{display:grid;grid-template-columns:1fr 1fr 1fr;gap:16px;padding:10px 12px 14px;border-top:1px solid rgba(255,255,255,.06)}
  .sliders .row{display:grid;grid-template-columns:auto 1fr auto;gap:8px;align-items:center}
  .sliders label{color:var(--muted);font-size:12px}
  input[type="range"]{width:100%}

  .log{height:420px;overflow:auto;padding:12px 14px;font:12px/1.5 ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;color:#cfe3ff}
  .log b{color:#80ffd9}
  .hint{padding:10px 14px;border-top:1px solid rgba(255,255,255,.06);color:var(--muted);font-size:12px}

  /* Lip debug crosshair (hidden by default) */
  .cross{position:absolute; width:14px;height:14px; margin:-7px 0 0 -7px;
         border-left:2px solid rgba(255,255,255,.35); border-top:2px solid rgba(255,255,255,.35);
         transform:rotate(45deg); display:none; pointer-events:none}
  .show-cross .cross{display:block}
</style>
</head>
<body>
<header>
  <h1>EmotiKnow — Emma (Voice Companion)</h1>
  <div class="sub">Click <b>Start</b> once to allow your microphone. Talk naturally; Emma replies in real time. Her portrait lip-syncs to the audio.</div>
</header>

<div class="wrap">
  <!-- LEFT: portrait -->
  <section class="card">
    <h3>Emma (portrait)</h3>
    <div class="stage" id="stage">
      <img id="portrait" class="portrait" src="/Emma_EmotiKnow_Companion.png" alt="Emma portrait" />
      <canvas id="overlay"></canvas>
      <div id="cross" class="cross"></div>
    </div>
    <div class="controls">
      <button id="start" class="primary">Start</button>
      <button id="hangup" class="">Hang Up</button>

      <select id="voice">
        <option value="shimmer" selected>Shimmer (female, bright)</option>
        <option value="coral">Coral (female, clear)</option>
        <option value="sage">Sage (female, soft)</option>
        <option value="marin">Marin (female, warm)</option>
        <option value="ballad">Ballad (feminine, lyrical)</option>
        <option value="verse">Verse (neutral)</option>
        <option value="alloy">Alloy (neutral)</option>
        <option value="echo">Echo</option>
        <option value="ash">Ash</option>
        <option value="cedar">Cedar</option>
      </select>

      <button id="testSpeaker" class="warn">Test speaker</button>
      <div id="status" style="margin-left:auto;color:var(--muted);font-size:12px">status: <b id="statusText">ended</b></div>
    </div>

    <!-- sliders -->
    <div class="sliders">
      <div class="row">
        <label>Lip size</label>
        <input id="lipSize" type="range" min="8" max="90" step="1">
        <span id="lipSizeVal" style="font-size:12px;color:var(--muted)"></span>
      </div>
      <div class="row">
        <label>Sensitivity</label>
        <input id="sensitivity" type="range" min="0" max="100" step="1">
        <span id="sensVal" style="font-size:12px;color:var(--muted)"></span>
      </div>
      <div class="row">
        <label>Gate</label>
        <input id="gate" type="range" min="0" max="100" step="1">
        <span id="gateVal" style="font-size:12px;color:var(--muted)"></span>
      </div>
    </div>

    <div class="hint">
      Tip: If you don’t hear Emma, click <b>Test speaker</b>, then click <b>Start</b> again (autoplay can be blocked).
      Click the portrait to re-anchor lips. Your position is saved to this browser.
    </div>
  </section>

  <!-- RIGHT: diagnostics -->
  <section class="card">
    <h3>Diagnostics</h3>
    <pre id="log" class="log"></pre>
  </section>
</div>

<script>
(() => {
  /* --------------------------- Elements & state --------------------------- */
  const startBtn = document.getElementById('start');
  const hangBtn  = document.getElementById('hangup');
  const testBtn  = document.getElementById('testSpeaker');
  const statusEl = document.getElementById('statusText');
  const voiceSel = document.getElementById('voice');

  const stage    = document.getElementById('stage');
  const img      = document.getElementById('portrait');
  const canvas   = document.getElementById('overlay');
  const ctx      = canvas.getContext('2d');
  const cross    = document.getElementById('cross');

  const logEl    = document.getElementById('log');

  const lipSize   = document.getElementById('lipSize');
  const lipSizeVal= document.getElementById('lipSizeVal');
  const sens      = document.getElementById('sensitivity');
  const sensVal   = document.getElementById('sensVal');
  const gate      = document.getElementById('gate');
  const gateVal   = document.getElementById('gateVal');

  // persistent settings
  const SKEY = 'emma-mouth-v1';
  let settings = {
    x: 523, y: 215,
    size: 26,        // radius in px at rest
    sensitivity: 55, // how strongly lips react to audio
    gate: 28         // minimum VU to open
  };
  try { Object.assign(settings, JSON.parse(localStorage.getItem(SKEY) || '{}')); } catch(e){}

  // peer/audio
  let pc = null, localStream = null, remoteAudio = null, audioCtx = null, analyser = null;

  /* --------------------------- UI helpers --------------------------- */
  function setStatus(s){ statusEl.textContent = s; }
  function log(...a){
    const t = new Date().toLocaleTimeString();
    logEl.textContent += `[${t}] ` + a.join(' ') + '\n';
    logEl.scrollTop = logEl.scrollHeight;
  }

  function saveSettings(){
    localStorage.setItem(SKEY, JSON.stringify(settings));
  }
  function updateSliderUI(){
    lipSize.value = settings.size;
    lipSizeVal.textContent = settings.size + ' px';
    sens.value = settings.sensitivity;
    sensVal.textContent = settings.sensitivity + '%';
    gate.value = settings.gate;
    gateVal.textContent = settings.gate + '%';
  }
  updateSliderUI();

  /* --------------------------- Canvas sizing --------------------------- */
  function fitCanvas(){
    // Match canvas to displayed image size
    const r = img.getBoundingClientRect();
    canvas.width = r.width;
    canvas.height = r.height;
    canvas.style.width = r.width + 'px';
    canvas.style.height = r.height + 'px';

    // Crosshair position
    cross.style.left = (settings.x / img.naturalWidth  * r.width)  + 'px';
    cross.style.top  = (settings.y / img.naturalHeight * r.height) + 'px';
  }
  new ResizeObserver(fitCanvas).observe(stage);
  img.addEventListener('load', fitCanvas);

  /* --------------------------- Mouth anchor --------------------------- */
  // click to set mouth center (in image/natural coordinates)
  stage.addEventListener('click', (e) => {
    const r = img.getBoundingClientRect();
    const cx = e.clientX - r.left;
    const cy = e.clientY - r.top;
    settings.x = Math.max(0, Math.min(img.naturalWidth,  cx / r.width  * img.naturalWidth));
    settings.y = Math.max(0, Math.min(img.naturalHeight, cy / r.height * img.naturalHeight));
    saveSettings();
    fitCanvas();
    log(`Saved mouth: x=${settings.x.toFixed(1)}, y=${settings.y.toFixed(1)}`);
  });

  lipSize.addEventListener('input', () => { settings.size = +lipSize.value; lipSizeVal.textContent = settings.size + ' px'; saveSettings(); });
  sens.addEventListener('input', () => { settings.sensitivity = +sens.value; sensVal.textContent = settings.sensitivity + '%'; saveSettings(); });
  gate.addEventListener('input', () => { settings.gate = +gate.value; gateVal.textContent = settings.gate + '%'; saveSettings(); });

  /* --------------------------- Lip animation (no stroke) --------------------------- */
  let vu = 0, smoothed = 0, rafId = 0;

  function drawLips(){
    ctx.clearRect(0,0,canvas.width,canvas.height);

    // Convert anchor from natural -> displayed pixel coords
    const r = img.getBoundingClientRect();
    const px = settings.x / img.naturalWidth  * r.width;
    const py = settings.y / img.naturalHeight * r.height;

    // Simple VU smoothing
    const open = Math.max(0, vu - settings.gate/100); // gate in 0..1 space
    smoothed = smoothed*0.85 + open*0.15;

    // radius grows a little with VU
    const base = settings.size; // px
    const radius = base + smoothed * (base*0.9) * (settings.sensitivity/100);

    // softly filled ellipse (NO STROKE)
    const fade = Math.min(0.55, 0.18 + smoothed*0.5); // 0..~0.55
    ctx.fillStyle = `rgba(255, 107, 129, ${fade})`; // soft rose fill only
    ctx.beginPath();
    ctx.ellipse(px, py, radius * 0.85, radius * 0.55, 0, 0, Math.PI*2);
    ctx.fill();

    rafId = requestAnimationFrame(drawLips);
  }

  /* --------------------------- Audio VU (from remote) --------------------------- */
  function attachVu(remoteMediaEl){
    if (audioCtx) audioCtx.close();
    audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    const src = audioCtx.createMediaElementSource(remoteMediaEl);
    analyser = audioCtx.createAnalyser();
    analyser.fftSize = 1024;
    src.connect(analyser);
    analyser.connect(audioCtx.destination);

    const buf = new Uint8Array(analyser.fftSize);
    function tick(){
      analyser.getByteTimeDomainData(buf);
      // Normalize to 0..1 (rough)
      let sum = 0;
      for (let i=0;i<buf.length;i++){
        const v = (buf[i]-128)/128;
        sum += v*v;
      }
      vu = Math.min(1, Math.sqrt(sum / buf.length) * 3.2); // boost a little
      requestAnimationFrame(tick);
    }
    tick();
  }

  /* --------------------------- WebRTC with OpenAI --------------------------- */
  async function startCall(){
    if (pc) await hangup();

    setStatus('starting…');
    log('Requesting microphone…');

    localStream = await navigator.mediaDevices.getUserMedia({audio:true});
    log('Mic granted.');

    pc = new RTCPeerConnection();
    localStream.getTracks().forEach(t => pc.addTrack(t, localStream));

    // remote audio sink
    pc.ontrack = (e) => {
      if (!remoteAudio){
        remoteAudio = new Audio();
        remoteAudio.autoplay = true;
        remoteAudio.srcObject = e.streams[0];
        attachVu(remoteAudio);
        log('Remote audio stream received.');
      }
    };

    pc.onconnectionstatechange = () => {
      log(`pc state: ${pc.connectionState}`);
      if (pc.connectionState === 'connected') setStatus('live');
      if (['disconnected','failed','closed'].includes(pc.connectionState)) setStatus('ended');
    };

    // 1) Get a short-lived client secret from our serverless function
    const voice = voiceSel.value;
    const tokenRes = await fetch(`/api/realtime-session?voice=${encodeURIComponent(voice)}`);
    if (!tokenRes.ok){ log('Error: Token endpoint error'); return; }
    const token = await tokenRes.json();
    log('Token response status: 200');

    // 2) Create local SDP
    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);

    // 3) Post SDP to OpenAI Realtime endpoint
    const url = `https://api.openai.com/v1/realtime?model=${encodeURIComponent('gpt-4o-mini-realtime-preview')}`;
    log('POSTing SDP to:', url);
    const sdpRes = await fetch(url,{
      method:'POST',
      headers:{
        'Authorization': `Bearer ${token.client_secret.value}`,
        'Content-Type': 'application/sdp'
      },
      body: offer.sdp
    });

    if (!sdpRes.ok){
      const body = await sdpRes.text().catch(()=> '');
      log('SDP POST status:', sdpRes.status);
      log('Token fetch failed body:', body.slice(0,400));
      return;
    }
    log('SDP POST status: 201');

    const answer = { type:'answer', sdp: await sdpRes.text() };
    await pc.setRemoteDescription(answer);

    setStatus('connecting');
    log(`Session established on gpt-4o-mini-realtime-preview. Voice: ${voice}.`);
  }

  async function hangup(){
    try { if (pc) pc.close(); } catch(e){}
    pc = null;
    if (remoteAudio){ try{ remoteAudio.srcObject = null; }catch(e){} }
    remoteAudio = null;
    setStatus('ended');
    log('Call ended. (user)');
  }

  /* --------------------------- Speaker test --------------------------- */
  testBtn.addEventListener('click', async () => {
    try{
      const ctx = new (window.AudioContext||window.webkitAudioContext)();
      const osc = ctx.createOscillator();
      const g = ctx.createGain();
      osc.type='triangle'; osc.frequency.value=880;
      g.gain.value=0.12; osc.connect(g); g.connect(ctx.destination);
      osc.start(); setTimeout(()=>{osc.stop(); ctx.close();}, 350);
    }catch(e){}
  });

  /* --------------------------- Wire controls --------------------------- */
  startBtn.addEventListener('click', startCall);
  hangBtn.addEventListener('click', hangup);

  // show faint crosshair briefly after load to confirm anchor (no white ring ever)
  window.addEventListener('load', () => {
    fitCanvas();
    document.body.classList.add('show-cross');
    setTimeout(()=>document.body.classList.remove('show-cross'), 900);
    log('Ready. Click Start and speak. If you do not hear audio, press Test speaker then Start again.');
    setStatus('ended');
    drawLips(); // start render loop
  });
})();
</script>
</body>
</html>
