<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>EmotiKnow — Emma (Voice Companion)</title>
  <style>
    :root{
      --bg:#0f1117; --panel:#151b23; --ink:#e6e8ef; --muted:#93a3b2; --accent:#8ab4ff;
      --ok:#22c55e; --warn:#f59e0b; --err:#ef4444;
    }
    *{box-sizing:border-box}
    html,body{height:100%}
    body{
      margin:0; background:var(--bg); color:var(--ink);
      font:500 15px/1.45 system-ui, Segoe UI, Roboto, "Helvetica Neue", Arial, "Noto Sans";
      display:grid; place-items:start center;
    }

    .wrap{width:min(1200px,100%); padding:18px}
    h1{font-weight:800; letter-spacing:.2px; margin:0 0 14px}
    .row{display:grid; grid-template-columns:1.2fr .85fr; gap:16px}
    @media (max-width:980px){ .row{grid-template-columns:1fr} }

    /* Stage */
    .stage{
      background:#000; border:1px solid #202937; border-radius:14px; overflow:hidden;
      position:relative; aspect-ratio:16/9; min-height:420px;
      display:grid; place-items:center; 
    }
    .portrait{
      width:100%; height:100%; object-fit:contain; background:#000;
      user-select:none; pointer-events:none;
    }

    /* Mouth overlay image (we swap the src) */
    #mouth{
      position:absolute;
      left:50%; top:50%;
      transform:translate(-50%,-50%);
      width:220px; /* will be changed by slider and anchored by click */
      filter:drop-shadow(0 0 1px rgba(0,0,0,.2));
      image-rendering:auto;  /* keep it smooth */
      pointer-events:none;   /* don't block clicks on portrait */
    }

    /* Side panel */
    .panel{
      background:var(--panel); border:1px solid #202937; border-radius:14px; padding:14px;
      display:grid; gap:14px; align-content:start; height:100%;
    }
    .btn{
      all:unset; cursor:pointer; text-align:center; padding:12px 14px; border-radius:10px;
      background:#1c2633; color:#fff; font-weight:700;
    }
    .btn:active{transform:translateY(1px)}
    .btn.secondary{background:#232f3f}
    label{display:grid; gap:6px; font-size:13px; color:var(--muted)}
    input[type="range"]{width:100%}
    select{width:100%; padding:10px; border-radius:10px; background:#10151d; color:#fff; border:1px solid #263242}
    .kv{display:flex; gap:8px; align-items:center}
    .dot{width:10px;height:10px;border-radius:99px;background:#334; box-shadow:0 0 0 2px #000 inset}
    .dot.live{background:var(--ok)}
    pre{
      background:#0b0f15; border:1px solid #202937; color:#a9b6c7;
      padding:10px; border-radius:10px; height:200px; overflow:auto; white-space:pre-wrap;
    }

    .tip{font-size:12px; color:#93a3b2}
  </style>
</head>
<body>
  <div class="wrap">
    <h1>EmotiKnow — Emma (Voice Companion)</h1>
    <div class="row">
      <!-- LEFT: video + mouth overlay -->
      <div class="stage" id="stage">
        <!-- Your background portrait (video or image). Keep as your current element or replace src. -->
        <video id="portrait" class="portrait" src="./emma_bg.mp4" autoplay muted loop playsinline></video>

        <!-- The mouth overlay we swap between frames -->
        <img id="mouth" alt="mouth overlay" src="/mouths/i2.png" />
      </div>

      <!-- RIGHT: controls -->
      <div class="panel">
        <div class="kv">
          <button class="btn" id="btnStart">Start</button>
          <button class="btn secondary" id="btnHang">Hang Up</button>
          <span class="dot" id="dot"></span>
        </div>

        <label>
          Target width (mouth)
          <input id="wSlider" type="range" min="80" max="420" step="2" value="220" />
        </label>

        <label>
          Smooth (higher = slower)
          <input id="smoothSlider" type="range" min="0" max="0.97" step="0.01" value="0.80" />
        </label>

        <label>
          Gate (ignore background)
          <input id="gateSlider" type="range" min="0" max="0.08" step="0.002" value="0.015" />
        </label>

        <label>
          Voice “personality”
          <select id="voiceSel">
            <option value="warm">Warm (gentle, kind)</option>
            <option value="bright">Shimmer (bright)</option>
          </select>
        </label>

        <label>
          VU
          <div class="tip"><span id="vu">—</span></div>
        </label>

        <div class="tip">Tip: Click Emma’s <b>real mouth</b> once to anchor the overlay. The position &amp; sizing are saved per browser.</div>
        <pre id="log">[app] ready.</pre>
      </div>
    </div>
  </div>

  <!-- Hidden audio element where Emma's voice plays -->
  <audio id="remoteAudio" autoplay playsinline></audio>

  <script>
    /***********************
     * CONFIG
     ***********************/
    const MOUTH_FRAMES = [
      "/mouth/i2.png", // closed
      "/mouth/m2.jpg", // mid
      "/mouth/o2.png", // open
      "/mouth/e2.jpg"  // teeth / wide
    ];

    const LS_KEY = "emma-mouth-anchor-v2"; // {x,y,width}
    const log = (...a)=>{ const el=document.getElementById('log'); el.textContent += "\n"+a.join(" "); el.scrollTop = el.scrollHeight; };

    /***********************
     * DOM
     ***********************/
    const stage   = document.getElementById('stage');
    const mouthEl = document.getElementById('mouth');
    const wSlider = document.getElementById('wSlider');
    const sSlider = document.getElementById('smoothSlider');
    const gSlider = document.getElementById('gateSlider');
    const dot     = document.getElementById('dot');
    const vuTxt   = document.getElementById('vu');
    const btnStart= document.getElementById('btnStart');
    const btnHang = document.getElementById('btnHang');
    const voiceSel= document.getElementById('voiceSel');
    const remote  = document.getElementById('remoteAudio');

    /***********************
     * STATE
     ***********************/
    let raf, analyser, dataArr, audioCtx, srcNode;
    let envSmoothed = 0;  // smoothed VU (0..1)
    let running = false;

    // Anchor: normalized coords of Emma's mouth center (0..1)
    let anchor = { x:.51, y:.34, width: +wSlider.value };

    // load anchor from localStorage
    try{
      const saved = JSON.parse(localStorage.getItem(LS_KEY));
      if (saved && typeof saved.x==="number") anchor = saved;
      wSlider.value = anchor.width || 220;
    }catch(e){}

    // apply anchor to element
    function applyAnchor() {
      const rect = stage.getBoundingClientRect();
      const cx = rect.width * anchor.x;
      const cy = rect.height* anchor.y;
      mouthEl.style.left = `${cx}px`;
      mouthEl.style.top  = `${cy}px`;
      mouthEl.style.width= `${anchor.width}px`;
    }
    applyAnchor();

    // click once to set anchor at cursor
    stage.addEventListener('click', (e)=>{
      const r = stage.getBoundingClientRect();
      anchor.x = (e.clientX - r.left) / r.width;
      anchor.y = (e.clientY - r.top)  / r.height;
      localStorage.setItem(LS_KEY, JSON.stringify(anchor));
      applyAnchor();
      log("[anchor] saved x="+anchor.x.toFixed(3)+", y="+anchor.y.toFixed(3));
    });

    // width slider
    wSlider.addEventListener('input', ()=>{
      anchor.width = +wSlider.value;
      localStorage.setItem(LS_KEY, JSON.stringify(anchor));
      applyAnchor();
    });

    /***********************
     * AUDIO -> VU METER
     ***********************/
    function setupAnalyser() {
      // stop previous ctx
      if (audioCtx) try{ audioCtx.close() }catch(e){}
      audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      analyser = audioCtx.createAnalyser();
      analyser.fftSize = 2048;
      dataArr = new Uint8Array(analyser.fftSize);

      srcNode = audioCtx.createMediaElementSource(remote);
      srcNode.connect(analyser);
      analyser.connect(audioCtx.destination); // so you can hear it
    }

    // compute RMS and map to 0..1
    function computeLevel(){
      analyser.getByteTimeDomainData(dataArr);
      let sum=0;
      for (let i=0;i<dataArr.length;i++){
        const v=(dataArr[i]-128)/128; sum += v*v;
      }
      const rms = Math.sqrt(sum/dataArr.length); // ~0..0.7
      return Math.min(1, rms/0.3); // normalize a bit hotter
    }

    /***********************
     * MOUTH FRAME SELECTION
     ***********************/
    function setMouthByLevel(level){
      // gate + smoothing
      const gate = +gSlider.value;           // ignore noise below this
      const smooth = +sSlider.value;         // 0 = instant, 0.97 = very slow
      const raw = (level < gate) ? 0 : (level - gate) / (1 - gate); // 0..1 after gate
      envSmoothed = envSmoothed * smooth + raw * (1 - smooth);

      // pick frame
      const idx = Math.min(MOUTH_FRAMES.length-1, Math.floor(envSmoothed * MOUTH_FRAMES.length));
      if (mouthEl.dataset.idx != idx){
        mouthEl.dataset.idx = idx;
        mouthEl.src = MOUTH_FRAMES[idx];
      }

      // tiny scale wiggle for life
      const scale = 0.98 + envSmoothed*0.05;
      mouthEl.style.transform = `translate(-50%,-50%) scale(${scale})`;

      vuTxt.textContent = envSmoothed.toFixed(3);
    }

    function loop(){
      if (!running) return;
      const lvl = computeLevel();
      setMouthByLevel(lvl);
      raf = requestAnimationFrame(loop);
    }

    /***********************
     * START / HANGUP
     ***********************/
    btnStart.addEventListener('click', async ()=>{
      if (running) return;
      // Get a session token from your Vercel route (already in your project)
      try{
        dot.classList.remove('live');
        log("[mic] requesting…");
        await navigator.mediaDevices.getUserMedia({audio:true}); // trigger permission once
        log("[mic] granted.");

        // Ask your serverless function for a temporary client_secret for Realtime
        const r = await fetch('/api/realtime-session', {method:'POST'});
        const j = await r.json();
        if (!j.client_secret?.value){ log("[error] token http "+r.status); return; }
        log("[token] ok.");

        // Connect Emma’s voice (your existing Realtime/WebRTC code should attach audio to #remoteAudio).
        // For this vanilla page, we assume your backend streams audio into remoteAudio.srcObject or src.
        // If you're already doing this elsewhere, keep it. Here we just mark UI live:
        setupAnalyser();
        envSmoothed = 0;
        running = true; dot.classList.add('live'); log("[sdp] handshake complete.");
        applyAnchor();
        loop();
      }catch(err){
        log("[error] "+(err?.message||err));
      }
    });

    btnHang.addEventListener('click', ()=>{
      running = false; cancelAnimationFrame(raf);
      if (audioCtx) try{ audioCtx.close() }catch(e){}
      dot.classList.remove('live');
      log("[call] ended.");
    });

    // keep mouth element in place on resize
    addEventListener('resize', applyAnchor);
  </script>
</body>
</html>
