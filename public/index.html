<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>EmotiKnow — Emma (Voice Companion)</title>
<style>
  :root{
    --bg:#0f1117; --panel:#131a24; --ink:#e6e8ef; --muted:#9aa3b2; --accent:#8ab4ff;
  }
  *{box-sizing:border-box}
  html,body{height:100%}
  body{
    margin:0; background:var(--bg); color:var(--ink);
    font:500 15px/1.5 ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, "Helvetica Neue";
    display:grid; place-items:start center;
  }
  .wrap{width:min(1100px,100%); padding:18px}
  h1{font-weight:800; letter-spacing:.2px; margin:0 0 10px 0; font-size:clamp(20px,2.6vw,28px)}
  .row{display:grid; grid-template-columns:1.1fr .9fr; gap:16px}
  @media (max-width:980px){ .row{grid-template-columns:1fr} }

  .stage{
    background:var(--panel);
    border:1px solid #1e2a3a; border-radius:14px; overflow:hidden;
    display:grid; place-items:center; padding:16px;
  }
  .frame{position:relative; width:100%; aspect-ratio:16/9; background:#000; display:grid; place-items:center;}
  .portrait{
    max-width:100%; max-height:100%; width:auto; height:100%;
    object-fit:contain; user-select:none; pointer-events:none;
  }
  /* Mouth overlay image (single sprite scaled by VU) */
  .mouth{
    position:absolute; left:50%; top:50%;
    transform:translate(-50%,-50%);
    width:200px; /* gets replaced by slider */
    opacity:.98; filter:drop-shadow(0 0 6px rgba(0,0,0,.25));
    pointer-events:none; /* only portrait click anchors */
  }
  .hint{ position:absolute; inset:auto 12px 12px 12px; color:var(--muted); font-size:13px; text-align:center; }

  .panel{
    background:var(--panel); border:1px solid #1e2a3a; border-radius:14px; padding:14px;
    display:grid; gap:14px; align-content:start;
  }
  .grid2{ display:grid; grid-template-columns:1fr 1fr; gap:12px}
  .grid3{ display:grid; grid-template-columns:1fr 1fr 1fr; gap:12px}
  label{ display:grid; gap:6px; font-size:13px; color:var(--muted)}
  input[type="range"]{ width:100% }
  select, button{
    background:#0f1520; color:var(--ink); border:1px solid #1f2a3a; border-radius:10px;
    padding:10px 12px; font-weight:600;
  }
  button.primary{ background:linear-gradient(180deg,#23324a,#182234); border-color:#243247}
  button:disabled{ opacity:.5; cursor:not-allowed}
  .vu{ height:6px; background:#111827; border-radius:8px; overflow:hidden}
  .vu > i{ display:block; height:100%; width:0%; background:linear-gradient(90deg,#79ffe1,#8ab4ff); transition:width .08s linear}
  pre{
    background:#0b111a; color:#bcd3ff; border:1px solid #172235; border-radius:10px;
    padding:10px; max-height:240px; overflow:auto; margin:0
  }
</style>
</head>
<body>
  <div class="wrap">
    <h1>EmotiKnow — Emma (Voice Companion)</h1>
    <div class="row">
      <section class="stage">
        <div class="frame" id="frame">
          <!-- Your portrait -->
          <img id="portrait" class="portrait" src="/m.png" alt="Emma portrait" />
          <!-- Single mouth sprite we scale by VU. Use any small PNG (transparent). -->
          <img id="mouth" class="mouth" src="/mouth/m.png" alt="mouth overlay" />
          <div class="hint">Tip: click Emma’s <b>real mouth</b> once to anchor the overlay. The position &amp; sizing are saved per browser.</div>
        </div>
      </section>

      <aside class="panel">
        <div class="grid2">
          <button id="startBtn" class="primary">Start</button>
          <button id="hangBtn">Hang Up</button>
        </div>

        <label>Target width (mouth)
          <input id="mouthWidth" type="range" min="80" max="600" step="1" value="240"/>
        </label>

        <label>Smooth (higher = slower)
          <input id="smooth" type="range" min="0" max="0.95" step="0.01" value="0.80"/>
        </label>

        <label>Gate (ignore background)
          <input id="gate" type="range" min="0" max="0.3" step="0.005" value="0.12"/>
        </label>

        <label>Voice “personality”
          <select id="voice">
            <!-- warm/friendly female defaults first -->
            <option value="aria">Aria (warm)</option>
            <option value="serene">Serene (gentle)</option>
            <option value="breeze">Breeze (soft)</option>
            <!-- brighter female -->
            <option value="shimmer">Shimmer (bright)</option>
            <!-- neutral -->
            <option value="verse">Verse (neutral)</option>
            <!-- mellow male if you ever want it -->
            <option value="ballad">Ballad (mellow)</option>
          </select>
        </label>

        <div class="vu" title="voice level"><i id="vu"></i></div>

        <pre id="log">[app] ready.</pre>
      </aside>
    </div>
  </div>

<script>
(() => {
  const $ = sel => document.querySelector(sel);
  const log = (m) => { logBox.textContent += "\n" + m; logBox.scrollTop = logBox.scrollHeight; };

  // Elements
  const frame = $("#frame");
  const portrait = $("#portrait");
  const mouth = $("#mouth");
  const startBtn = $("#startBtn");
  const hangBtn  = $("#hangBtn");
  const widthSlider = $("#mouthWidth");
  const smoothSlider = $("#smooth");
  const gateSlider   = $("#gate");
  const voiceSel     = $("#voice");
  const vuBar        = $("#vu");
  const logBox       = $("#log");

  // Mouth anchor (click once to save)
  let mouthX = 0.5; // normalized [0..1]
  let mouthY = 0.58;
  // Persist anchor per browser
  try {
    const st = localStorage.getItem("emoti_anchor");
    if (st) { const {x,y} = JSON.parse(st); mouthX = x; mouthY = y; }
  } catch {}

  // Positioning + sizing
  function layoutMouth(){
    mouth.style.width = widthSlider.value + "px";
    // Convert normalized to px inside the portrait box
    const rect = portrait.getBoundingClientRect();
    const pr = frame.getBoundingClientRect(); // viewport inside frame
    // portrait may not fill frame exactly; compute its rendered box
    const w = portrait.clientWidth;
    const h = portrait.clientHeight;
    const left = (frame.clientWidth - w)/2 + w*mouthX;
    const top  = (frame.clientHeight - h)/2 + h*mouthY;
    mouth.style.left = left + "px";
    mouth.style.top  = top  + "px";
  }
  window.addEventListener("resize", layoutMouth);
  portrait.addEventListener("load", layoutMouth);
  widthSlider.addEventListener("input", layoutMouth);

  // Click to (re)anchor
  frame.addEventListener("click", (e) => {
    // compute click normalized coords relative to portrait’s rendered box
    const box = portrait.getBoundingClientRect();
    const fx  = (e.clientX - box.left)/box.width;
    const fy  = (e.clientY - box.top)/box.height;
    if (fx>=0 && fx<=1 && fy>=0 && fy<=1) {
      mouthX = fx; mouthY = fy;
      localStorage.setItem("emoti_anchor", JSON.stringify({x:mouthX,y:mouthY}));
      layoutMouth();
      log(`[anchor] saved x=${mouthX.toFixed(3)}, y=${mouthY.toFixed(3)}`);
    }
  }, false);

  // WebRTC bits
  let pc, micStream, remoteStream, audioEl, analyser, rafId;
  let smooth = parseFloat(smoothSlider.value);  // 0..0.95
  let gate   = parseFloat(gateSlider.value);    // 0..0.30
  let vu     = 0;

  smoothSlider.addEventListener("input", ()=> smooth = parseFloat(smoothSlider.value));
  gateSlider.addEventListener("input",   ()=> gate   = parseFloat(gateSlider.value));

  function resetMouth(){
    // small shrink so it doesn’t look frozen open
    mouth.style.transform = "translate(-50%,-50%) scale(0.92)";
  }

  function animateLipSync(){
    if (!analyser) return;
    const buf = new Uint8Array(analyser.fftSize);
    analyser.getByteTimeDomainData(buf);

    // RMS energy
    let sum = 0;
    for (let i=0;i<buf.length;i++){
      const v = (buf[i]-128)/128; // -1..1
      sum += v*v;
    }
    const rms = Math.sqrt(sum / buf.length);

    // gate & smoothing
    const level = Math.max(0, rms - gate) / (1 - gate);
    vu = (1 - smooth)*level + smooth*vu;

    // Update VU bar and mouth scale
    vuBar.style.width = Math.min(100, (vu*100).toFixed(1)) + "%";

    const scale = 0.90 + vu * 0.35; // 0.9..1.25
    mouth.style.transform = `translate(-50%,-50%) scale(${scale.toFixed(3)})`;

    rafId = requestAnimationFrame(animateLipSync);
  }

  async function start(){
    startBtn.disabled = true;
    try{
      // 1) mic
      log("[mic] requesting…");
      micStream = await navigator.mediaDevices.getUserMedia({ audio:true });
      log("[mic] granted.");

      // 2) peer
      pc = new RTCPeerConnection();
      micStream.getTracks().forEach(t => pc.addTrack(t, micStream));

      // 3) remote audio + analyser
      remoteStream = new MediaStream();
      pc.addEventListener("track", (ev) => {
        remoteStream.addTrack(ev.track);
      });

      // we attach audio element *after* connection to avoid autoplay blocks
      audioEl = new Audio();
      audioEl.autoplay = true;
      audioEl.srcObject = remoteStream;

      // 4) set up WebAudio to read remote volume
      const ctx = new (window.AudioContext || window.webkitAudioContext)();
      const src = ctx.createMediaStreamSource(remoteStream);
      analyser  = ctx.createAnalyser();
      analyser.fftSize = 512;
      src.connect(analyser);

      // 5) SDP offer → our API → OpenAI → answer
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);

      const voice = voiceSel.value || "aria";
      log("[token] fetching…");
      const r = await fetch(`/api/realtime-session?voice=${encodeURIComponent(voice)}`, {
        method: "POST",
        headers: { "Content-Type": "application/sdp" },
        body: offer.sdp
      });
      const answerSdp = await r.text();
      if (!r.ok) {
        log(`[error] ${answerSdp}`);
        throw new Error("Realtime API error");
      }

      await pc.setRemoteDescription({ type:"answer", sdp: answerSdp });
      log("[sdp] handshake complete.");

      pc.addEventListener("connectionstatechange", () => {
        log(`[pc] state: ${pc.connectionState}`);
        if (pc.connectionState === "failed" || pc.connectionState === "closed" || pc.connectionState === "disconnected"){
          hang();
        }
      });

      // kick the animator
      cancelAnimationFrame(rafId);
      animateLipSync();
    }catch(err){
      console.error(err);
      log("[error] " + (err?.message || err));
      startBtn.disabled = false;
    }
  }

  async function hang(){
    cancelAnimationFrame(rafId);
    try { audioEl && (audioEl.srcObject = null); } catch {}
    try { micStream && micStream.getTracks().forEach(t=>t.stop()); } catch {}
    try { pc && pc.close(); } catch {}
    pc = micStream = remoteStream = analyser = null;
    resetMouth();
    log("[call] ended.");
    startBtn.disabled = false;
  }

  startBtn.addEventListener("click", start);
  hangBtn .addEventListener("click", hang);

  // First layout
  layoutMouth();
  resetMouth();
})();
</script>
</body>
</html>
