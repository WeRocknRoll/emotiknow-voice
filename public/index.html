<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>EmotiKnow — Emma (Voice Companion)</title>
<style>
  :root{
    --bg:#0f1117; --panel:#151b23; --ink:#e6e8ef; --muted:#93a3b2; --accent:#8ab4ff; --ok:#22c55e; --warn:#ef4444;
  }
  *{box-sizing:border-box}
  html,body{height:100%}
  body{
    margin:0; background:var(--bg); color:var(--ink);
    font:500 15px/1.45 ui-sans-serif,system-ui,Segoe UI,Roboto,Helvetica Neue,Arial;
    display:grid; place-items:start center;
  }
  .wrap{width:min(1200px,100%); padding:18px}
  h1{font-weight:800; letter-spacing:.2px; margin:0 0 14px}
  .row{display:grid; grid-template-columns:1.05fr .95fr; gap:16px}
  @media (max-width:1040px){ .row{grid-template-columns:1fr} }

  .panel{
    background:var(--panel); border:1px solid #202937; border-radius:14px; padding:14px;
    box-shadow:0 10px 30px rgba(0,0,0,.25);
  }
  .stage{
    display:grid; place-items:center; background:#0a0d12; border-radius:12px; padding:12px;
    min-height:420px; overflow:hidden;
  }
  canvas, video, img{max-width:100%; height:auto; display:block}
  .portrait{
    position:relative; width:100%; max-width:980px; aspect-ratio:16/9; background:#000; overflow:hidden; border-radius:10px;
  }
  .portrait img{width:100%; height:100%; object-fit:cover}
  /* mouth overlay */
  .mouth{
    position:absolute; left:50%; top:50%; width:260px; transform:translate(-50%,-50%);
    pointer-events:none; mix-blend-mode:screen; opacity:.0; transition:opacity .25s ease, width .25s ease;
  }
  .controls label{display:block; font-size:12px; color:var(--muted); margin:10px 0 4px}
  .controls input[type="range"]{width:100%}
  .btns{display:flex; gap:10px; margin:0 0 4px}
  button{
    background:#101826; color:var(--ink); border:1px solid #223047; border-radius:10px;
    padding:10px 14px; font-weight:700; cursor:pointer;
  }
  button.primary{background:#1a2334; border-color:#35527f}
  select{width:100%; padding:10px; background:#101826; color:var(--ink); border:1px solid #223047; border-radius:10px}
  .diag{white-space:pre-wrap; background:#0b0f16; border:1px solid #1e293b; border-radius:10px; padding:10px; height:210px; overflow:auto}
  .vu{height:8px; background:#122031; border:1px solid #223047; border-radius:999px; position:relative; overflow:hidden; margin-top:6px}
  .vu > i{position:absolute; left:0; top:0; bottom:0; width:2%; background:linear-gradient(90deg,#3ee98a,#8ab4ff); border-radius:999px}
  .tip{font-size:12px; color:var(--muted)}
</style>
</head>
<body>
<div class="wrap">
  <h1>EmotiKnow — Emma (Voice Companion)</h1>

  <div class="row">
    <!-- Left: portrait -->
    <div class="panel stage">
      <div class="portrait" id="portrait">
        <img id="emma" alt="Emma" src="./m.png" />
        <!-- nine-frame mouth spritesheet (480x240 recommended, 9 frames horizontal) -->
        <img id="mouth" class="mouth" src="./mouth.png" alt="mouth overlay" />
      </div>
    </div>

    <!-- Right: controls -->
    <div class="panel">
      <div class="btns">
        <button id="start" class="primary">Start</button>
        <button id="hangup">Hang Up</button>
      </div>

      <div class="controls">
        <label>Target width (mouth)</label>
        <input id="mouthWidth" type="range" min="140" max="520" step="1" value="260" />

        <label>Smooth (higher = slower)</label>
        <input id="smooth" type="range" min="0" max="100" step="1" value="70" />

        <label>Gate (ignore background)</label>
        <input id="gate" type="range" min="0" max="100" step="1" value="18" />

        <label>Voice “personality”</label>
        <select id="voiceSel">
          <option value="shimmer|Warm, gentle, kind caregiving. Short and encouraging.">Warm (gentle, kind)</option>
          <option value="aria|Brighter, upbeat, friendly coach. Keep replies short.">Bright (friendly)</option>
        </select>

        <label>VU</label>
        <div class="vu"><i id="vu"></i></div>

        <p class="tip">Tip: Click Emma’s <b>real mouth</b> once to anchor the overlay. The position &amp; sizing are saved per browser.</p>

        <div class="diag" id="log">[app] ready.</div>
      </div>
    </div>
  </div>
</div>

<script>
/* ---- tiny logger ---- */
const logEl = document.getElementById('log');
const say = (...a)=>{ logEl.textContent += '\n' + a.join(' '); logEl.scrollTop = logEl.scrollHeight; };

/* ---- UI elements ---- */
const portrait = document.getElementById('portrait');
const mouthImg = document.getElementById('mouth');
const startBtn = document.getElementById('start');
const hangBtn  = document.getElementById('hangup');
const widthCtl = document.getElementById('mouthWidth');
const smoothCtl= document.getElementById('smooth');
const gateCtl  = document.getElementById('gate');
const voiceSel = document.getElementById('voiceSel');
const vuBar    = document.getElementById('vu');

/* ---- anchor saving per browser ---- */
let anchor = JSON.parse(localStorage.getItem('emma_anchor')||'null');
portrait.addEventListener('click', (e)=>{
  const rect = portrait.getBoundingClientRect();
  const x = (e.clientX - rect.left) / rect.width;
  const y = (e.clientY - rect.top)  / rect.height;
  anchor = {x,y};
  localStorage.setItem('emma_anchor', JSON.stringify(anchor));
  positionMouth();
  say('[anchor] saved x=' + x.toFixed(3) + ', y=' + y.toFixed(3));
});
function positionMouth(){
  if(!anchor) return;
  const rect = portrait.getBoundingClientRect();
  const W = +widthCtl.value;
  mouthImg.style.width = W + 'px';
  mouthImg.style.left  = (anchor.x*rect.width) + 'px';
  mouthImg.style.top   = (anchor.y*rect.height) + 'px';
  mouthImg.style.transform = 'translate(-50%,-50%)';
}
widthCtl.oninput = positionMouth;

/* ---- simple VU from mic ---- */
let audioContext, analyser, micStream;
function setupVU(stream){
  audioContext = new (window.AudioContext||window.webkitAudioContext)();
  const src = audioContext.createMediaStreamSource(stream);
  analyser = audioContext.createAnalyser();
  analyser.fftSize = 1024;
  src.connect(analyser);

  const data = new Uint8Array(analyser.frequencyBinCount);
  function tick(){
    if(!analyser) return;
    analyser.getByteTimeDomainData(data);
    let sum = 0;
    for(let i=0;i<data.length;i++){ const v = (data[i]-128)/128; sum += v*v; }
    const rms = Math.sqrt(sum/data.length); // 0..~0.5
    vuBar.style.width = Math.min(100, Math.max(2, (rms*220))) + '%';
    requestAnimationFrame(tick);
  }
  tick();
}

/* ---- Realtime call over WebRTC ---- */
let pc, mic;
async function startCall(){
  try{
    // get mic first (so user grants permission early)
    mic = await navigator.mediaDevices.getUserMedia({ audio:true });
    setupVU(mic);
    say('[mic] granted.');

    // fetch a short-lived client secret from our API
    const s = await fetch('/api/realtime-session', { method:'POST' })
      .then(r=>r.json());
    if (!s?.client_secret?.value) {
      say('[error] token', JSON.stringify(s));
      throw new Error('No client secret from server.');
    }
    say('[token] ok.');

    // Configure peer connection
    pc = new RTCPeerConnection();
    // remote audio out
    pc.ontrack = (ev)=>{
      // play the assistant’s audio
      const audioEl = document.createElement('audio');
      audioEl.autoplay = true; audioEl.srcObject = ev.streams[0];
      document.body.appendChild(audioEl);
    };

    // add our mic to the peer
    mic.getTracks().forEach(t => pc.addTrack(t, mic));

    // DataChannel (optional; could be used to stream mouth cues later)
    pc.createDataChannel('oai-events');

    // Create SDP offer
    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);

    // Exchange SDP with OpenAI Realtime using the client secret
    const base = 'https://api.openai.com/v1/realtime';
    const r = await fetch(`${base}?model=${encodeURIComponent(s.model)}`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${s.client_secret.value}`,
        'Content-Type': 'application/sdp'
      },
      body: offer.sdp
    });

    if (!r.ok) {
      const text = await r.text().catch(()=> '');
      say('[error] sdp', text);
      throw new Error('Realtime SDP exchange failed.');
    }

    const answerSdp = await r.text();
    await pc.setRemoteDescription({ type:'answer', sdp: answerSdp });
    say('[sdp] handshake complete.');

    // warm persona prompt (soft, kind)
    const sel = voiceSel.value.split('|');
    const voice = sel[0];           // 'shimmer' or 'aria'
    const system = sel.slice(1).join('|') || 'Warm and kind. Keep replies brief.';
    await fetch(`${base}/messages`, {
      method:'POST',
      headers:{
        'Authorization': `Bearer ${s.client_secret.value}`,
        'Content-Type':'application/json'
      },
      body: JSON.stringify({
        instructions: system
      })
    }).catch(()=>{}); // non-blocking

    // show mouth overlay (we’ll animate it a bit from the VU)
    mouthImg.style.opacity = 0.9;
  }catch(err){
    say('[error] ' + err.message);
  }
}

function hangup(){
  if (pc) { pc.close(); pc = null; }
  if (micStream) micStream.getTracks().forEach(t=>t.stop());
  mouthImg.style.opacity = 0.0;
  say('[call] ended.');
}

/* ---- basic lip “pulse” using VU only (no phoneme stream) ---- */
(function animateMouth(){
  // size changes follow VU bar a bit
  const pct = parseFloat(vuBar.style.width || '2') || 2;
  const w = (+widthCtl.value) * (0.9 + pct/600); // slight open
  mouthImg.style.width = w.toFixed(1) + 'px';
  positionMouth();
  requestAnimationFrame(animateMouth);
})();

/* ---- wire up ---- */
startBtn.onclick = ()=>{ say('[frames] loaded 9/9 (single overlay mode)'); positionMouth(); startCall(); };
hangBtn.onclick  = hangup;
window.addEventListener('resize', positionMouth);
document.addEventListener('DOMContentLoaded', positionMouth);
</script>
</body>
</html>
