<audio id="remoteAudio" autoplay playsinline></audio>

<script>
  const logEl = document.getElementById("log");
  const statusEl = document.getElementById("status");
  const startBtn = document.getElementById("start");
  const hangupBtn = document.getElementById("hangup");
  const remoteAudio = document.getElementById("remoteAudio");

  let pc = null, localStream = null, audioCtx = null, noSpeechTimer = null;

  function log(msg){
    const p = document.createElement("div");
    p.textContent = `[${new Date().toLocaleTimeString()}] ${msg}`;
    logEl.appendChild(p);
    logEl.scrollTop = logEl.scrollHeight;
  }
  function setStatus(s){ statusEl.textContent = s; }

  // Helper: (re)start the "no speech" timer
  function armNoSpeechTimer(ms = 20000){           // 20s (was 8s)
    clearNoSpeechTimer();
    noSpeechTimer = setTimeout(() => {
      log(`No user speech for ${ms/1000}s — ending to save cost`);
      hangup();
    }, ms);
  }
  function clearNoSpeechTimer(){
    if (noSpeechTimer) clearTimeout(noSpeechTimer);
    noSpeechTimer = null;
  }

  async function start(){
    try {
      // 1) Create/Resume AudioContext so the browser is allowed to play audio
      audioCtx = audioCtx || new (window.AudioContext || window.webkitAudioContext)();
      if (audioCtx.state === "suspended") await audioCtx.resume();

      // 2) Ask for microphone
      setStatus("requesting mic…");
      localStream = await navigator.mediaDevices.getUserMedia({
        audio: { echoCancellation: true, noiseSuppression: true, autoGainControl: true }
      });
      setStatus("mic granted");

      // Arm no-speech timeout as soon as we have a mic
      armNoSpeechTimer();

      // 3) Fetch a realtime token from our server
      const tokenRes = await fetch(`/api/realtime-session?voice=${encodeURIComponent(document.getElementById('voice').value || 'shimmer')}`);
      const token = await tokenRes.json();
      if (!token?.client_secret?.value) {
        log("Failed to get token");
        return;
      }

      // 4) Create PeerConnection
      pc = new RTCPeerConnection();

      // 5) Attach REMOTE audio
      pc.ontrack = (e) => {
        log(`ontrack received (kind=${e.track.kind})`);
        remoteAudio.srcObject = e.streams[0];
        remoteAudio.muted = false;
        remoteAudio.volume = 1.0;
        const p = remoteAudio.play();
        if (p && typeof p.then === "function") {
          p.catch(err => log("audio play blocked: " + err.message));
        }
      };

      // Optional: see ICE progress
      pc.oniceconnectionstatechange = () => log("ice: " + pc.iceConnectionState);
      pc.onconnectionstatechange    = () => log("pc state: " + pc.connectionState);

      // 6) Add LOCAL mic tracks to PC
      localStream.getTracks().forEach(t => pc.addTrack(t, localStream));

      // 7) Create offer & set local description
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);

      // 8) Send SDP to OpenAI Realtime, get answer
      const baseUrl = "https://api.openai.com/v1/realtime";
      const model   = "gpt-4o-mini-realtime-preview";
      const sdpRes = await fetch(`${baseUrl}?model=${model}`, {
        method: "POST",
        headers: {
          "Content-Type": "application/sdp",
          "Authorization": `Bearer ${token.client_secret.value}`,
          "OpenAI-Beta": "realtime=v1"
        },
        body: offer.sdp
      });

      const answer = { type: "answer", sdp: await sdpRes.text() };
      await pc.setRemoteDescription(answer);

      log(`Session established on ${model}. Voice: ${document.getElementById('voice').value}`);

      // 9) Anytime we detect mic data flowing, keep the line alive
      localStream.getAudioTracks().forEach(track => {
        track.onended    = () => log("mic track ended");
        track.onmute     = () => log("mic muted");
        track.onunmute   = () => log("mic unmuted");
        track.onisolationchange = () => log("mic isolation change");
      });

      // 10) Reset no-speech timer when we detect user start speaking (via volume meter)
      // Lightweight meter
      const meterSrc = audioCtx.createMediaStreamSource(localStream);
      const analyser = audioCtx.createAnalyser();
      analyser.fftSize = 256;
      meterSrc.connect(analyser);
      const data = new Uint8Array(analyser.frequencyBinCount);
      (function pump(){
        analyser.getByteTimeDomainData(data);
        // crude voice activity check
        let maxDev = 0;
        for (let i=0;i<data.length;i++){
          const dev = Math.abs(data[i]-128);
          if (dev > maxDev) maxDev = dev;
        }
        if (maxDev > 8) armNoSpeechTimer(); // user made a sound -> extend timer
        if (pc && pc.connectionState !== "closed") requestAnimationFrame(pump);
      })();

    } catch (err) {
      log("Error: " + (err?.message || err));
      hangup();
    }
  }

  function hangup(){
    try {
      if (pc) {
        pc.getSenders().forEach(s => { try { s.track && s.track.stop(); } catch{} });
        pc.close();
      }
      if (localStream) localStream.getTracks().forEach(t => t.stop());
    } catch {}
    pc = null;
    localStream = null;
    clearNoSpeechTimer();
    log("Call ended.");
    setStatus("ended");
  }

  document.getElementById("voice").addEventListener("change", () => log("voice: " + document.getElementById("voice").value));
  startBtn.onclick = start;
  hangupBtn.onclick = hangup;
</script>
