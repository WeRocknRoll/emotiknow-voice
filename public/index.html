<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>EmotiKnow – Emma (Voice Companion)</title>
  <style>
    body{font-family:system-ui,-apple-system,Segoe UI,Roboto,sans-serif;max-width:840px;margin:40px auto;padding:0 16px}
    .btn{padding:12px 18px;border-radius:10px;border:0;background:#6d28d9;color:#fff;font-weight:600;cursor:pointer}
    #status{margin-left:10px;color:#4b5563}
    #log{margin-top:18px;background:#f8fafc;border-radius:12px;padding:12px;height:240px;overflow:auto;border:1px solid #e5e7eb;font-size:14px;line-height:1.4}
    .row{display:flex;gap:10px;align-items:center;flex-wrap:wrap;margin-top:12px}
    .select{padding:10px;border-radius:10px;border:1px solid #e5e7eb}
    label{display:flex;align-items:center;gap:6px}
  </style>
</head>
<body>
  <h1>EmotiKnow – Emma (Voice Companion)</h1>
  <p>Click <b>Start</b> and talk naturally. Emma uses a cheaper model when possible and falls back automatically if needed.</p>

  <div class="row">
    <button id="start" class="btn">Start</button>
    <button id="hangup" class="btn" style="background:#ef6c00;">Hang Up</button>

    <label>Voice:
      <select id="voice" class="select">
        <option value="shimmer" selected>Shimmer (female, bright)</option>
        <option value="coral">Coral (female, clear)</option>
        <option value="sage">Sage (female, soft)</option>
        <option value="marin">Marin (female, warm)</option>
        <option value="ballad">Ballad (feminine, lyrical)</option>
        <option value="verse">Verse (neutral)</option>
        <option value="alloy">Alloy (neutral)</option>
        <option value="echo">Echo</option>
        <option value="ash">Ash</option>
        <option value="cedar">Cedar</option>
      </select>
    </label>

    <label>Max session:
      <select id="maxmins" class="select">
        <option value="20" selected>20 min</option>
        <option value="30">30 min</option>
        <option value="10">10 min</option>
      </select>
    </label>

    <span id="status">idle</span>
  </div>

  <audio id="remoteAudio" autoplay></audio>
  <div id="log"></div>

  <script>
    // -------- Models & Policies --------
    const MINI_MODEL = "gpt-4o-mini-realtime-preview";
    const FULL_MODEL = "gpt-4o-realtime-preview"; // fallback
    const SILENCE_CUTOFF_MS = 8000;   // end session on 8s of user silence (saves $)
    const WATCHDOG_QUIET_MS = 20000;  // try ICE restart if quiet 20s

    // -------- State --------
    let restarting = false, disconnectTimer = null, icedOnce = false;
    let lastAnyActivity = Date.now();
    let keepAliveInterval = null, silenceTimer = null, sessionEndTimer = null;

    const logEl = document.getElementById("log");
    const statusEl = document.getElementById("status");
    const startBtn = document.getElementById("start");
    const hangupBtn = document.getElementById("hangup");
    const voiceSel = document.getElementById("voice");
    const maxminsSel = document.getElementById("maxmins");
    const remoteAudio = document.getElementById("remoteAudio");

    let pc = null, localStream = null, audioCtx = null, analyser = null, micSource = null, rafId = null;

    function log(msg){ const p=document.createElement("div"); p.textContent=`[${new Date().toLocaleTimeString()}] ${msg}`; logEl.appendChild(p); logEl.scrollTop=logEl.scrollHeight; }
    function setStatus(s){ statusEl.textContent = s; }
    function setMicEnabled(enabled){ if (!localStream) return; localStream.getAudioTracks().forEach(t => t.enabled = enabled); }

    function startSilenceTimer() { clearSilenceTimer(); silenceTimer = setTimeout(() => { log(`No user speech for ${SILENCE_CUTOFF_MS/1000}s — ending to save cost`); hangup(); }, SILENCE_CUTOFF_MS); }
    function clearSilenceTimer() { if (silenceTimer) { clearTimeout(silenceTimer); silenceTimer=null; } }
    function startSessionEndTimer(minutes){ clearSessionEndTimer(); sessionEndTimer = setTimeout(()=>{ log(`Session limit ${minutes} min reached — ending`); hangup(); }, minutes*60*1000); }
    function clearSessionEndTimer(){ if (sessionEndTimer){ clearTimeout(sessionEndTimer); sessionEndTimer=null; } }

    startBtn.onclick = start;
    hangupBtn.onclick = hangup;
    hangupBtn.disabled = true;

    async function start() {
      startBtn.disabled = true; hangupBtn.disabled = false;

      try {
        setStatus("requesting mic…");
        localStream = await navigator.mediaDevices.getUserMedia({
          audio: { echoCancellation: true, noiseSuppression: true, autoGainControl: true }
        });
        setStatus("mic granted");

        // AudioContext must be resumed on user gesture (autoplay policy)
        audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        await audioCtx.resume();

        // Simple mic analyser to detect speech (for silence cutoff)
        const src = audioCtx.createMediaStreamSource(localStream);
        analyser = audioCtx.createAnalyser(); analyser.fftSize = 2048; src.connect(analyser);
        const buf = new Uint8Array(analyser.frequencyBinCount);
        const tick = () => {
          analyser.getByteTimeDomainData(buf);
          let sum=0; for (let i=0;i<buf.length;i++){ const v=(buf[i]-128)/128; sum+=v*v; }
          const rms=Math.sqrt(sum/buf.length);
          if (rms>0.02){ lastAnyActivity=Date.now(); startSilenceTimer(); }
          rafId=requestAnimationFrame(tick);
        };
        rafId=requestAnimationFrame(tick);

        // Try mini first, then auto-fallback to full model
        const v = voiceSel.value || "shimmer";
        const okMini = await establishSessionWithModel(v, MINI_MODEL);
        if (!okMini) {
          log("Mini model failed — trying full model…");
          const okFull = await establishSessionWithModel(v, FULL_MODEL);
          if (!okFull) throw new Error("Both models failed to establish a session");
        }

        setStatus("live (hands-free) ✨");
        startSilenceTimer();
        const maxMins = parseInt(maxminsSel.value || "20", 10);
        startSessionEndTimer(maxMins);

        // Keep-alive: poke stats every 10s; if quiet for 20s, nudge ICE
        if (keepAliveInterval) clearInterval(keepAliveInterval);
        keepAliveInterval = setInterval(async () => {
          try { await pc?.getStats?.(); } catch {}
          if (pc && pc.connectionState === "connected" && Date.now()-lastAnyActivity > WATCHDOG_QUIET_MS) {
            log("Watchdog: quiet for 20s — attempting ICE restart");
            try { pc.restartIce?.(); } catch {}
            lastAnyActivity = Date.now();
          }
        }, 10000);

      } catch (err) {
        log("Error: " + err);
        setStatus("error");
        startBtn.disabled = false; hangupBtn.disabled = true;
      }
    }

    async function establishSessionWithModel(voice, modelName) {
      try {
        // Get ephemeral token (server returns JSON or a clear error JSON)
        const tokenRes = await fetch(`/api/realtime-session?voice=${encodeURIComponent(voice)}&model=${encodeURIComponent(modelName)}`);
        if (!tokenRes.ok) { log(`Token error (${modelName}) [${tokenRes.status}]: ${await tokenRes.text()}`); return false; }
        const token = await tokenRes.json();
        if (!token?.client_secret?.value) { log(`No client_secret for ${modelName}`); return false; }

        // Peer connection
        pc = new RTCPeerConnection();

        // Audio: on incoming track, attach and force play (fix autoplay)
        pc.ontrack = (e) => {
          remoteAudio.srcObject = e.streams[0];
          remoteAudio.muted = false;
          remoteAudio.play().catch(err => log("Audio play blocked: " + err));
          lastAnyActivity = Date.now();
        };

        pc.oniceconnectionstatechange = () => { log("ice: " + pc.iceConnectionState); lastAnyActivity = Date.now(); };

        // Robust connection state handling (ICE restart → full restart)
        pc.onconnectionstatechange = () => {
          log("pc state: " + pc.connectionState);

          if (pc.connectionState === "failed" && !restarting) {
            restarting = true; log("Connection failed — restarting…");
            setTimeout(() => { hangup(); start(); restarting = false; }, 600);
          }

          if (pc.connectionState === "disconnected") {
            if (!icedOnce) { icedOnce = true; try { log("Disconnected — attempting ICE restart"); pc.restartIce?.(); } catch {} }
            if (!disconnectTimer) {
              disconnectTimer = setTimeout(() => {
                if (pc && pc.connectionState === "disconnected" && !restarting) {
                  restarting = true; log("Still disconnected — restarting…");
                  hangup(); start(); restarting = false;
                }
                disconnectTimer = null;
              }, 2500);
            }
          } else {
            icedOnce = false;
            if (disconnectTimer) { clearTimeout(disconnectTimer); disconnectTimer = null; }
          }
        };

        // Echo guard (half-duplex): mute mic while Emma speaks
        remoteAudio.addEventListener("playing", () => { setMicEnabled(false); });
        let resumeTimer = null;
        const resumeMic = () => { setMicEnabled(true); startSilenceTimer(); };
        remoteAudio.addEventListener("pause", () => { if (resumeTimer) clearTimeout(resumeTimer); resumeTimer = setTimeout(resumeMic, 400); });
        remoteAudio.addEventListener("timeupdate", () => {
          if (remoteAudio.paused) return;
          const almostDone = remoteAudio.duration && (remoteAudio.duration - remoteAudio.currentTime < 0.35);
          if (almostDone) { if (resumeTimer) clearTimeout(resumeTimer); resumeTimer = setTimeout(resumeMic, 300); }
        });

        // Send mic upstream
        localStream.getTracks().forEach(t => pc.addTrack(t, localStream));

        // Offer/Answer with chosen model
        const offer = await pc.createOffer();
        await pc.setLocalDescription(offer);

        const sdpRes = await fetch(`https://api.openai.com/v1/realtime?model=${encodeURIComponent(modelName)}`, {
          method: "POST",
          headers: {
            "Authorization": `Bearer ${token.client_secret.value}`,
            "Content-Type": "application/sdp",
            "OpenAI-Beta": "realtime=v1"
          },
          body: offer.sdp
        });

        const answerText = await sdpRes.text();
        if (!sdpRes.ok) {
          log(`SDP error (${modelName}) [${sdpRes.status}]: ${answerText}`);
          try { pc.close(); } catch {}
          pc = null;
          return false;
        }

        await pc.setRemoteDescription({ type: "answer", sdp: answerText });
        log(`Session established on ${modelName}. Voice: ${voice}.`);
        // Force play once more (some browsers need it after SRD)
        remoteAudio.play().catch(err => log("Audio play (post-answer) blocked: " + err));
        return true;
      } catch (e) {
        log(`establishSessionWithModel(${modelName}) failed: ` + e);
        try { pc?.close(); } catch {}
        pc = null;
        return false;
      }
    }

    function hangup() {
      try {
        if (pc) pc.close();
        if (localStream) localStream.getTracks().forEach(t => t.stop());
        if (rafId) cancelAnimationFrame(rafId);
        if (audioCtx) audioCtx.close();
        if (keepAliveInterval) clearInterval(keepAliveInterval);
        clearSilenceTimer(); clearSessionEndTimer();
      } finally {
        pc = null; localStream = null; audioCtx = null; analyser = null; micSource = null; rafId = null;
        restarting = false; icedOnce = false;
        setStatus("ended"); log("Call ended.");
        startBtn.disabled = false; hangupBtn.disabled = true;
      }
    }
  </script>
</body>
</html>
